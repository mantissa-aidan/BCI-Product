{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neuroprosthetic Alert System (BCI Nurse Call Device).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tY8qu2-u_x6_",
        "OvtgPk7aAT66",
        "jiFeVYR1ArUZ",
        "mte5135zAkyc",
        "efrcUqrGnpIv"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mantissa-aidan/BCI-Product/blob/master/Neuroprosthetic_Alert_System_(BCI_Nurse_Call_Device).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjTLp-Hq_3OR",
        "outputId": "13b483f1-984c-4ff5-c772-428531511979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD4iVFWh_V6u",
        "outputId": "2d02185f-3c36-44ad-fbd6-2b747a3b7ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#something like\n",
        "\n",
        "%cd /content/drive/My Drive/DATA3888"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/DATA3888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgpUNTWieh7f"
      },
      "source": [
        "# Neuroprosthetic Alert System (BCI Nurse Call Device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOOmmnsFsntG"
      },
      "source": [
        "\n",
        "Brain-Computer Interfaces (BCI) enable signals from the human brain to be communicated to a machine in a way that specific signals would translate to a command which the machine is then meant to carry out. Research in BCI have been taking place since the 1970s and its main focus has been on developing neuroprosthetics applications to benefit those with physical disabilities [1]. At present the BCI devices that have been developed require conscious effort to be controlled. However the aim of research in this field is to develop applications that can be controlled by humans effortlessly. Correspondingly, the main aim of this project is to develop a product that depends on eye-movement signals to seamlessly carry out a practical application.\n",
        " \n",
        "This report specifically focuses on the development of a nurse call device using eye-movement signals in real-time. With many developments in the health sector geared towards people with physical disabilities, one recent improvement of the nurse-call button in hospitals, has been a device which can recognise from a patient’s speech if he/she is calling the nurse and then notify a nurse accordingly[2]. While such a device is ideal for those with physical disabilities, it excludes those who may have speech impediments. Taking this into consideration, the product introduced in this report is geared towards those for whom eye-movement may be the main form of communication.\n",
        " \n",
        "The main issues in regards to developing such a product are the following:\n",
        "1.     Conducting the relevant physiological measurements and collecting the data accurately\n",
        "2.     Recognising when a measurement/physiological data corresponds to a specific practical command in real-time.\n",
        " \n",
        "The first issue deals with the problem of data collection. This project made use of an Arduino from Backyard Brains which collected eye-movement signals. While collecting eye-movement data from a person is not too difficult various considerations need to be made when using this data to build a product that can be generally used to carry out tasks. Firstly, the product should be able to correctly identify when a person is making a left or right eye-movement, for example, even when the data collected is quite noisy. This necessitates effective data preprocessing. Secondly, the product should be able to recognise left and right eye-movement for different people. This requires the product to be trained on, and thereby requires the collection of, a large and diverse dataset.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://i.ytimg.com/vi/LYcITvxYB1I/hqdefault.jpg\" alt=\"BYB Spikerbox\" width=450/>\n",
        "</center>\n",
        "\n",
        "The second issue deals with building a classifier that is able to not only accurately predict what type of eye-movement a certain incoming signal corresponds to, but also do this fast enough in real-time for its practical function to be effective. In this particular project, therefore, a classifier needed to be built that could recognise if a patient made a specific eye-movement sequence that translates to the command to call a nurse. The classifier would need to recognise this accurately and quickly so that the notification can be sent to the nurse in time. \n",
        "\n",
        "Below are the details of how the above two issues were addressed in this project. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N34PLzFRk00l",
        "cellView": "both"
      },
      "source": [
        "#@title BCI NURSE CALL DEVICE"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-A-XD-U8JcN",
        "cellView": "both",
        "outputId": "9b55aa7b-bd7e-4f75-81ad-a88601ab17f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "\n",
        "from scipy.io import wavfile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, LSTM\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "bigdata = pd.read_csv(\"raw_samples.txt\", sep=\",\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mky85Q8kT4d"
      },
      "source": [
        "#Data Collection and Preprocessing\n",
        "\n",
        "The data used to train the classifier used in this project were collected using the arduino interfaced with Python. Electrodes were placed on the forehead and temple of the user and these detected the corneo-retinal standing potential between front and back of the eye, indicating whether the person moved their eyes left or right. The signals incoming from the user was recorded in one second recordings and about 130 recordings were collected for each of left movements, right movements, and no movement. As the data was being recorded, a Fourier transform was applied to denoise the signals. These enabled better recognition of the features corresponding to a left or right eye movement. Each of the recordings were then labeled by hand to avoid incorrect labeling and were combined into one dataset to be used to build different classifiers of the eye-movement. \n",
        "\n",
        "Effectively collecting data for this project was dependent on first implementing the real time stream of data from the BYB Spikerbox. It was important to ensure that the data we were using for development would be as close as possible to the data we would classify on deployment. Therefore before we trained any models. We needed data that was filtered using our FT denoising, centred around zero and subset to a prediction window that we chose.\n",
        "\n",
        "Since the BYB Spikerbox had a sampling rate of 10kHz, we chose a 9990 step window of observations to predict, as this corresponded to a time series of just under 1 second of eye movement data. We then refreshed this window every 1/10th of a second which gave us a rolling window 1 second window of data:\n",
        "\n",
        "###Visualisation of data stream\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1_HDOKHHc8u-ND0p3Cl57R78KiEZI-q2t\" alt=\"Data stream\" width=450/>\n",
        "</center>\n",
        "\n",
        "We were provided with R code that split and labelled the recordings based on the zero crossing of the waveform and expected we could implement this into our model testing development. However this code was incompatible with our workflow for the following reasons.\n",
        "\n",
        "1.   The code was written in R and used the R tsfeatures package which has no implementation in Python, so it could not be implemented into our existing code base.\n",
        "\n",
        "2.   The code split and labelled WAV files which were recorded through the BYB Spikerbox software. When the BYB Spikerbox recorded and saved data, it downsampled these recordings using a method that was not documented. As a result there was a significant difference between training data created using Spikerbox WAV files and real-time data being streamed in using a Python/numpy implementation.\n",
        "\n",
        "3.  The code used a zero crossing method of splitting and labelling the data. We tested this labelled data on two-class versions of the same classification models we implemented later in the project. We consistenly found no greater than 52% accuracy using this labelling method on our own recordings which we verfied with cross validation. When we inspected the labelling, we saw that this code had incorrectly labelled left/right movements.\n",
        "\n",
        "As a result of these issues we had to recreate an entirely new dataset, we simply saved the contents of our realtime rolling window (post filtering and centering) as text files and labelled them by visual inspection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lv4kjX9mPoc"
      },
      "source": [
        "#Model Development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbB6n5B_X1ky"
      },
      "source": [
        "##Workflow \n",
        "\n",
        "The model development process was an iterative one represented by the diagram below. \n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1kSQDZlsAvOsZITig365emIzu4-aaWJxG\" alt=\"Data stream\" width=450/>\n",
        "</center>\n",
        "\n",
        "During the first iteration of data collection and model building, around 60 samples were recorded for left, right no eye movement each. These recordings were then labelled using the zero-crossing method on R. These labeled samples were then used as training data to build a preliminary keras neural network on R and the in-sample and out-of-sample accuracy. While the in-sample accuracy was found to be 7% while the out-of-sample accuracy was 52.2%. This low prediction accuracy necessitated reviewing the labelling of the training data and it was found that many of the recordings had been labeled incorrectly and it was decided that this was due to presence of noise in the data and due to errors in the design of the zero-crossing labeling method. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ5aQPUkRcOP"
      },
      "source": [
        "%load_ext rpy2.ipython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvqTFOPYBlGi",
        "outputId": "5214db0d-07ff-4e79-f4e6-736c1c1a67b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%R\n",
        "install.packages('tsfeatures')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnPJVSwJRgMM",
        "outputId": "d17b2596-c2f7-448b-e557-5df32c2779be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "#@title R code for initial Neural Network classifier\n",
        "%%R\n",
        "mydir <- list.files(\"LEFT_scaled\", recursive=TRUE, full.names=TRUE)\n",
        "\n",
        "signals_list_left <- list()\n",
        "\n",
        "for(i in 1: length(mydir)){\n",
        "  txtfile<- read.table(mydir[i], header = TRUE, sep = \"\\t\", dec = \".\")\n",
        "  txtfile$x <- as.character(txtfile$x)\n",
        "  lst <- strsplit(txtfile$x,\" \")\n",
        "  list <- as.numeric(sapply(lst, '[[', 2) )\n",
        "  signals_list_left <- c(signals_list_left, list(list))\n",
        "}\n",
        "\n",
        "left_labels <- rep(\"L\",length(mydir))\n",
        "\n",
        "mydir_right <- list.files(\"RIGHT_scaled\", recursive=TRUE, full.names=TRUE)\n",
        "\n",
        "signals_list_right <- list()\n",
        "\n",
        "for(i in 1: length(mydir_right)){\n",
        "  txtfile<- read.table(mydir_right[i], header = TRUE, sep = \"\\t\", dec = \".\")\n",
        "  txtfile$x <- as.character(txtfile$x)\n",
        "  lst <- strsplit(txtfile$x,\" \")\n",
        "  list <- as.numeric(sapply(lst, '[[', 2) )\n",
        "  signals_list_right <- c(signals_list_right, list(list))\n",
        "}\n",
        "\n",
        "right_labels <- rep(\"R\",length(mydir_right))\n",
        "\n",
        "Y_list1 <- c()\n",
        "Y_labels <- c()\n",
        "Y_list1 <- c(signals_list_left, signals_list_right)\n",
        "Y_labels <- c(left_labels, right_labels)\n",
        "\n",
        "Y_labels[c(1,3)]\n",
        "set.seed(111)\n",
        "indexes <- sample(length(Y_list1))\n",
        "length(indexes)\n",
        "#Y_data<- Y_data[sample(nrow(Y_data)),]\n",
        "Y_list1 <- Y_list1[indexes]\n",
        "Y_labels <- Y_labels[indexes]\n",
        "library(tsfeatures)\n",
        "Y2_features <- cbind(tsfeatures(Y_list1, c(\"acf_features\", \"entropy\", \"lumpiness\", \n",
        "    \"flat_spots\", \"crossing_points\")), tsfeatures(Y_list1, \"max_kl_shift\", width = 48), \n",
        "    tsfeatures(Y_list1, c(\"mean\", \"var\"), scale = FALSE, na.rm = TRUE), tsfeatures(Y_list1, \n",
        "        c(\"max_level_shift\", \"max_var_shift\"), trim = TRUE))\n",
        "\n",
        "Y2_features$class <- c(as.character(Y_labels))\n",
        "train_idx <- sample(nrow(Y2_features), round(0.8 * nrow(Y2_features)))\n",
        "\n",
        "X_train <- as.matrix((Y2_features[train_idx, 1:18]))\n",
        "y_train <- as.numeric(as.factor(Y2_features[train_idx, 19]))\n",
        "\n",
        "X_test <- as.matrix((Y2_features[-train_idx, 1:18]))\n",
        "y_test <- as.numeric(as.factor(Y2_features[-train_idx, 19]))\n",
        "\n",
        "\n",
        "range01 <- function(x) {\n",
        "    (x - min(x))/(max(x) - min(x))\n",
        "}\n",
        "X_train <- apply(X_train, 2, range01)\n",
        "X_test <- apply(X_test, 2, range01)\n",
        "\n",
        "\n",
        "\n",
        "model <- keras_model_sequential()\n",
        "model %>% layer_dense(units = 256, activation = \"relu\", input_shape = c(18)) %>% \n",
        "    layer_dense(units = 64, activation = \"relu\") %>% layer_dense(units = 10, \n",
        "    activation = \"softmax\")\n",
        "\n",
        "model %>% compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimizer_rmsprop(), \n",
        "    metrics = c(\"accuracy\"))\n",
        "\n",
        "model_fit <- model %>% fit(X_train, y_train, epochs = 30, batch_size = 10, validation_split = 0.2)\n",
        "model %>% evaluate(X_train, y_train)\n",
        "model %>% evaluate(X_test, y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Registered S3 method overwritten by 'xts':\n",
            "  method     from\n",
            "  as.zoo.xts zoo \n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Registered S3 method overwritten by 'quantmod':\n",
            "  method            from\n",
            "  as.zoo.data.frame zoo \n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Registered S3 methods overwritten by 'forecast':\n",
            "  method             from    \n",
            "  fitted.fracdiff    fracdiff\n",
            "  residuals.fracdiff fracdiff\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in keras_model_sequential() : \n",
            "  could not find function \"keras_model_sequential\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Error in keras_model_sequential() : \n",
            "  could not find function \"keras_model_sequential\"\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owx6QFrGRamz"
      },
      "source": [
        "In the second iteration the filter (that makes use of the Fourier transform) was revised its denoising performance was found to have greatly improved. This training data was then labeled by hand and was used to build multiple classifiers. The accuracy of these were calculated through k-fold cross-validation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYpRdkH6U2XR"
      },
      "source": [
        "#Building Classifiers (include cross-validation results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY8qu2-u_x6_"
      },
      "source": [
        "###Neural Network without feature extraction\n",
        "\n",
        "This was the application of the artificial neural network algorithm from the Keras package. The dataset was randomised then split into training and testing data of size 90% and 10% respectively and 2 hidden layers were constructed with 150 and 10 neurons in each hidden layer. This model architecture produced accuracy of 85.6% when predictions were made on the testing set. \n",
        "\n",
        "The number of hyperparameters such as the number of layers/neurons were changed around to observe its effect on validation accuracy. It was found that there was little difference between the validation accuracy of different combinations of hyperparameters. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsU9TRSUkuGq",
        "outputId": "8db2fcaa-12b6-4cbd-9001-56892600f196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#@title Code\n",
        "# first neural network with keras tutorial\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "y = pd.get_dummies(bigdata['class'])\n",
        "X = bigdata.drop(['class'], axis = 1)\n",
        "X = X.drop(['Unnamed: 0'], axis = 1)\n",
        "# Split the dataset to trainand test data\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.1,random_state=0)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(GRU(50, return_sequences=True, input_shape=(feature_train.shape[1],1)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GRU(100, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation = \"linear\"))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "print ('model compiled')\n",
        "# compile the keras model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit the keras model on the dataset\n",
        "model.fit(train_X, train_y, epochs=150, batch_size=10)\n",
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(test_X, test_y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 150/150\n",
            "208/208 [==============================] - 0s 447us/step - loss: 0.098 - acc: 0.8589\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "Accuracy: 85.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvtgPk7aAT66"
      },
      "source": [
        "###K-Nearest Neighbours\n",
        "\n",
        "Using the same method of splitting of the dataset into training and testing sets as described above, the KNeighborsClassifier from the scikit learn package was also applied. Various values for the number of neighbours parameter were used and it was found that the highest validation accuracy that could be obtained was 81.8%. Among the neighbour numbers that produced this accuracy, one value was 5. Thus this was the value of the n_neighbors parameter that was used for the purposes of reporting results in this report. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffnSE0ejAXNu",
        "cellView": "both",
        "outputId": "614bd893-bfe6-41d1-80a4-88e540c53fc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Code\n",
        "y = bigdata['class']\n",
        "X = bigdata.drop(['class'], axis = 1)\n",
        "X = X.drop(['Unnamed: 0'], axis = 1)\n",
        "# Split the dataset to trainand test data\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.1,random_state=0)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#Create KNN Classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "#Train the model using the training sets\n",
        "knn.fit(train_X, train_y)\n",
        "#Predict the response for test dataset\n",
        "y_pred = knn.predict(test_X)\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiFeVYR1ArUZ"
      },
      "source": [
        "###Random Forest (without feature extraction)\n",
        "\n",
        "Splitting the dataset into training and testing sets of 9:1 ratio again, a Random Forest classifier was built using the scikit learn package in Python. The number of trees in the forest was varied to observe the corresponding variations in validation accuracy. The validation accuracy found to little variation for different number of trees and the highest accuracy was found to be 86.4% given by a model with 10 000 trees. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHPawKvhAwt6",
        "outputId": "6a0cd180-4fff-4857-8107-b1f5d858e103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Code\n",
        "RF = RandomForestClassifier(n_estimators=10000, max_depth=10, random_state=0).fit(train_X, train_y)\n",
        "RF.predict(test_X)\n",
        "round(RF.score(test_X, test_y), 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD0Yr3wBneMJ"
      },
      "source": [
        "###Feature extraction using tsfresh\n",
        "\n",
        "From the above it can be observed that the GRU neural network had the best performance accuracy, however since performance is factor in our application we chose to use the random-forest model as it has faster runtime prediction.\n",
        "\n",
        "We settled on a multi-class classification model that could detected if a movement was \"Left', 'Right' or 'Neither'.\n",
        "\n",
        "In an attempt to improve the model, we decided to use an automatic time series feature extraction package called `tsfresh` that we had found. `tsfresh` can be configured to compute a large number of features, select only those that are statistically signficant for a classification task and return a data frame of those calculated features.\n",
        "\n",
        "Since we found that a Random Forest model produced the best accuracy method, we furthertested its performance on a range of different features produced by tsfresh and verified the robustness of the model using 20-fold cross validation.\n",
        "\n",
        "We compared the cross-validation results for models created using three types of feature extraction of the tsfresh package. The first model uses no feature extraction, the second model uses 'Minimal Feature Extraction' and the last model uses 'Efficient Feature Extraction'. While the minimal feature extraction extracts simple features such as minimum value, mean and median, the efficient feature extraction selects 1000 features which are the most statistically significant with regard to influencing a classifier. The code for each cross-validation is shown below. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB5db86fDFWy"
      },
      "source": [
        "###Random Forest with tsfresh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukl5FhniDFnB",
        "outputId": "7500f76b-0214-4ed7-9857-345fe67cff5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        }
      },
      "source": [
        "#@title Code - No Feature Extraction\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, LSTM, GRU\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "raw_samples  = pd.read_csv(\"raw_samples.txt\", index_col = 0)\n",
        "raw_samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>9951</th>\n",
              "      <th>9952</th>\n",
              "      <th>9953</th>\n",
              "      <th>9954</th>\n",
              "      <th>9955</th>\n",
              "      <th>9956</th>\n",
              "      <th>9957</th>\n",
              "      <th>9958</th>\n",
              "      <th>9959</th>\n",
              "      <th>9960</th>\n",
              "      <th>9961</th>\n",
              "      <th>9962</th>\n",
              "      <th>9963</th>\n",
              "      <th>9964</th>\n",
              "      <th>9965</th>\n",
              "      <th>9966</th>\n",
              "      <th>9967</th>\n",
              "      <th>9968</th>\n",
              "      <th>9969</th>\n",
              "      <th>9970</th>\n",
              "      <th>9971</th>\n",
              "      <th>9972</th>\n",
              "      <th>9973</th>\n",
              "      <th>9974</th>\n",
              "      <th>9975</th>\n",
              "      <th>9976</th>\n",
              "      <th>9977</th>\n",
              "      <th>9978</th>\n",
              "      <th>9979</th>\n",
              "      <th>9980</th>\n",
              "      <th>9981</th>\n",
              "      <th>9982</th>\n",
              "      <th>9983</th>\n",
              "      <th>9984</th>\n",
              "      <th>9985</th>\n",
              "      <th>9986</th>\n",
              "      <th>9987</th>\n",
              "      <th>9988</th>\n",
              "      <th>9989</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>FT_samples/left/signal.out105</th>\n",
              "      <td>-0.138383</td>\n",
              "      <td>-0.273093</td>\n",
              "      <td>-0.407333</td>\n",
              "      <td>-0.541104</td>\n",
              "      <td>-0.674404</td>\n",
              "      <td>-0.807233</td>\n",
              "      <td>-0.939592</td>\n",
              "      <td>-1.071480</td>\n",
              "      <td>-1.202897</td>\n",
              "      <td>-1.333842</td>\n",
              "      <td>-1.464316</td>\n",
              "      <td>-1.594318</td>\n",
              "      <td>-1.723847</td>\n",
              "      <td>-1.852905</td>\n",
              "      <td>-1.981490</td>\n",
              "      <td>-2.109603</td>\n",
              "      <td>-2.237243</td>\n",
              "      <td>-2.364411</td>\n",
              "      <td>-2.491106</td>\n",
              "      <td>-2.617328</td>\n",
              "      <td>-2.743077</td>\n",
              "      <td>-2.868353</td>\n",
              "      <td>-2.993156</td>\n",
              "      <td>-3.117485</td>\n",
              "      <td>-3.241342</td>\n",
              "      <td>-3.364726</td>\n",
              "      <td>-3.487636</td>\n",
              "      <td>-3.610074</td>\n",
              "      <td>-3.732038</td>\n",
              "      <td>-3.853529</td>\n",
              "      <td>-3.974548</td>\n",
              "      <td>-4.095093</td>\n",
              "      <td>-4.215166</td>\n",
              "      <td>-4.334766</td>\n",
              "      <td>-4.453893</td>\n",
              "      <td>-4.572548</td>\n",
              "      <td>-4.690731</td>\n",
              "      <td>-4.808441</td>\n",
              "      <td>-4.925679</td>\n",
              "      <td>-5.042446</td>\n",
              "      <td>...</td>\n",
              "      <td>5.630209</td>\n",
              "      <td>5.477098</td>\n",
              "      <td>5.324434</td>\n",
              "      <td>5.172219</td>\n",
              "      <td>5.020453</td>\n",
              "      <td>4.869137</td>\n",
              "      <td>4.718272</td>\n",
              "      <td>4.567858</td>\n",
              "      <td>4.417897</td>\n",
              "      <td>4.268388</td>\n",
              "      <td>4.119333</td>\n",
              "      <td>3.970733</td>\n",
              "      <td>3.822587</td>\n",
              "      <td>3.674897</td>\n",
              "      <td>3.527664</td>\n",
              "      <td>3.380887</td>\n",
              "      <td>3.234568</td>\n",
              "      <td>3.088707</td>\n",
              "      <td>2.943305</td>\n",
              "      <td>2.798363</td>\n",
              "      <td>2.653880</td>\n",
              "      <td>2.509858</td>\n",
              "      <td>2.366298</td>\n",
              "      <td>2.223198</td>\n",
              "      <td>2.080561</td>\n",
              "      <td>1.938387</td>\n",
              "      <td>1.796676</td>\n",
              "      <td>1.655429</td>\n",
              "      <td>1.514646</td>\n",
              "      <td>1.374328</td>\n",
              "      <td>1.234474</td>\n",
              "      <td>1.095087</td>\n",
              "      <td>0.956165</td>\n",
              "      <td>0.817710</td>\n",
              "      <td>0.679722</td>\n",
              "      <td>0.542201</td>\n",
              "      <td>0.405147</td>\n",
              "      <td>0.268562</td>\n",
              "      <td>0.132445</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/left/signal.out13</th>\n",
              "      <td>-15.727242</td>\n",
              "      <td>-15.693789</td>\n",
              "      <td>-15.660584</td>\n",
              "      <td>-15.627625</td>\n",
              "      <td>-15.594914</td>\n",
              "      <td>-15.562451</td>\n",
              "      <td>-15.530236</td>\n",
              "      <td>-15.498269</td>\n",
              "      <td>-15.466550</td>\n",
              "      <td>-15.435080</td>\n",
              "      <td>-15.403857</td>\n",
              "      <td>-15.372884</td>\n",
              "      <td>-15.342158</td>\n",
              "      <td>-15.311682</td>\n",
              "      <td>-15.281454</td>\n",
              "      <td>-15.251475</td>\n",
              "      <td>-15.221745</td>\n",
              "      <td>-15.192263</td>\n",
              "      <td>-15.163030</td>\n",
              "      <td>-15.134046</td>\n",
              "      <td>-15.105311</td>\n",
              "      <td>-15.076824</td>\n",
              "      <td>-15.048586</td>\n",
              "      <td>-15.020597</td>\n",
              "      <td>-14.992856</td>\n",
              "      <td>-14.965363</td>\n",
              "      <td>-14.938119</td>\n",
              "      <td>-14.911123</td>\n",
              "      <td>-14.884374</td>\n",
              "      <td>-14.857874</td>\n",
              "      <td>-14.831621</td>\n",
              "      <td>-14.805616</td>\n",
              "      <td>-14.779858</td>\n",
              "      <td>-14.754348</td>\n",
              "      <td>-14.729084</td>\n",
              "      <td>-14.704067</td>\n",
              "      <td>-14.679296</td>\n",
              "      <td>-14.654772</td>\n",
              "      <td>-14.630493</td>\n",
              "      <td>-14.606461</td>\n",
              "      <td>...</td>\n",
              "      <td>-17.220900</td>\n",
              "      <td>-17.178121</td>\n",
              "      <td>-17.135569</td>\n",
              "      <td>-17.093247</td>\n",
              "      <td>-17.051153</td>\n",
              "      <td>-17.009290</td>\n",
              "      <td>-16.967658</td>\n",
              "      <td>-16.926258</td>\n",
              "      <td>-16.885090</td>\n",
              "      <td>-16.844155</td>\n",
              "      <td>-16.803453</td>\n",
              "      <td>-16.762987</td>\n",
              "      <td>-16.722755</td>\n",
              "      <td>-16.682758</td>\n",
              "      <td>-16.642998</td>\n",
              "      <td>-16.603475</td>\n",
              "      <td>-16.564189</td>\n",
              "      <td>-16.525141</td>\n",
              "      <td>-16.486331</td>\n",
              "      <td>-16.447760</td>\n",
              "      <td>-16.409429</td>\n",
              "      <td>-16.371339</td>\n",
              "      <td>-16.333488</td>\n",
              "      <td>-16.295879</td>\n",
              "      <td>-16.258511</td>\n",
              "      <td>-16.221385</td>\n",
              "      <td>-16.184501</td>\n",
              "      <td>-16.147861</td>\n",
              "      <td>-16.111463</td>\n",
              "      <td>-16.075309</td>\n",
              "      <td>-16.039399</td>\n",
              "      <td>-16.003733</td>\n",
              "      <td>-15.968312</td>\n",
              "      <td>-15.933136</td>\n",
              "      <td>-15.898206</td>\n",
              "      <td>-15.863521</td>\n",
              "      <td>-15.829081</td>\n",
              "      <td>-15.794888</td>\n",
              "      <td>-15.760942</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/left/signal.out178</th>\n",
              "      <td>9.991873</td>\n",
              "      <td>9.988105</td>\n",
              "      <td>9.984327</td>\n",
              "      <td>9.980541</td>\n",
              "      <td>9.976745</td>\n",
              "      <td>9.972942</td>\n",
              "      <td>9.969130</td>\n",
              "      <td>9.965310</td>\n",
              "      <td>9.961481</td>\n",
              "      <td>9.957645</td>\n",
              "      <td>9.953801</td>\n",
              "      <td>9.949949</td>\n",
              "      <td>9.946090</td>\n",
              "      <td>9.942223</td>\n",
              "      <td>9.938349</td>\n",
              "      <td>9.934467</td>\n",
              "      <td>9.930579</td>\n",
              "      <td>9.926684</td>\n",
              "      <td>9.922782</td>\n",
              "      <td>9.918874</td>\n",
              "      <td>9.914959</td>\n",
              "      <td>9.911038</td>\n",
              "      <td>9.907111</td>\n",
              "      <td>9.903178</td>\n",
              "      <td>9.899239</td>\n",
              "      <td>9.895295</td>\n",
              "      <td>9.891344</td>\n",
              "      <td>9.887389</td>\n",
              "      <td>9.883429</td>\n",
              "      <td>9.879463</td>\n",
              "      <td>9.875492</td>\n",
              "      <td>9.871517</td>\n",
              "      <td>9.867538</td>\n",
              "      <td>9.863553</td>\n",
              "      <td>9.859565</td>\n",
              "      <td>9.855573</td>\n",
              "      <td>9.851576</td>\n",
              "      <td>9.847576</td>\n",
              "      <td>9.843573</td>\n",
              "      <td>9.839566</td>\n",
              "      <td>...</td>\n",
              "      <td>10.134058</td>\n",
              "      <td>10.130732</td>\n",
              "      <td>10.127393</td>\n",
              "      <td>10.124041</td>\n",
              "      <td>10.120677</td>\n",
              "      <td>10.117300</td>\n",
              "      <td>10.113911</td>\n",
              "      <td>10.110510</td>\n",
              "      <td>10.107096</td>\n",
              "      <td>10.103670</td>\n",
              "      <td>10.100232</td>\n",
              "      <td>10.096781</td>\n",
              "      <td>10.093319</td>\n",
              "      <td>10.089845</td>\n",
              "      <td>10.086359</td>\n",
              "      <td>10.082861</td>\n",
              "      <td>10.079352</td>\n",
              "      <td>10.075830</td>\n",
              "      <td>10.072298</td>\n",
              "      <td>10.068754</td>\n",
              "      <td>10.065199</td>\n",
              "      <td>10.061632</td>\n",
              "      <td>10.058055</td>\n",
              "      <td>10.054466</td>\n",
              "      <td>10.050866</td>\n",
              "      <td>10.047256</td>\n",
              "      <td>10.043635</td>\n",
              "      <td>10.040003</td>\n",
              "      <td>10.036361</td>\n",
              "      <td>10.032708</td>\n",
              "      <td>10.029045</td>\n",
              "      <td>10.025372</td>\n",
              "      <td>10.021689</td>\n",
              "      <td>10.017996</td>\n",
              "      <td>10.014292</td>\n",
              "      <td>10.010580</td>\n",
              "      <td>10.006857</td>\n",
              "      <td>10.003125</td>\n",
              "      <td>9.999384</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/left/signal.out106</th>\n",
              "      <td>48.399120</td>\n",
              "      <td>48.360541</td>\n",
              "      <td>48.321152</td>\n",
              "      <td>48.280958</td>\n",
              "      <td>48.239963</td>\n",
              "      <td>48.198169</td>\n",
              "      <td>48.155582</td>\n",
              "      <td>48.112203</td>\n",
              "      <td>48.068039</td>\n",
              "      <td>48.023092</td>\n",
              "      <td>47.977366</td>\n",
              "      <td>47.930866</td>\n",
              "      <td>47.883595</td>\n",
              "      <td>47.835558</td>\n",
              "      <td>47.786758</td>\n",
              "      <td>47.737200</td>\n",
              "      <td>47.686887</td>\n",
              "      <td>47.635825</td>\n",
              "      <td>47.584017</td>\n",
              "      <td>47.531467</td>\n",
              "      <td>47.478181</td>\n",
              "      <td>47.424161</td>\n",
              "      <td>47.369412</td>\n",
              "      <td>47.313940</td>\n",
              "      <td>47.257747</td>\n",
              "      <td>47.200839</td>\n",
              "      <td>47.143220</td>\n",
              "      <td>47.084895</td>\n",
              "      <td>47.025867</td>\n",
              "      <td>46.966142</td>\n",
              "      <td>46.905724</td>\n",
              "      <td>46.844618</td>\n",
              "      <td>46.782828</td>\n",
              "      <td>46.720359</td>\n",
              "      <td>46.657215</td>\n",
              "      <td>46.593402</td>\n",
              "      <td>46.528924</td>\n",
              "      <td>46.463785</td>\n",
              "      <td>46.397991</td>\n",
              "      <td>46.331547</td>\n",
              "      <td>...</td>\n",
              "      <td>49.241001</td>\n",
              "      <td>49.237374</td>\n",
              "      <td>49.232824</td>\n",
              "      <td>49.227351</td>\n",
              "      <td>49.220957</td>\n",
              "      <td>49.213646</td>\n",
              "      <td>49.205419</td>\n",
              "      <td>49.196279</td>\n",
              "      <td>49.186227</td>\n",
              "      <td>49.175266</td>\n",
              "      <td>49.163398</td>\n",
              "      <td>49.150625</td>\n",
              "      <td>49.136951</td>\n",
              "      <td>49.122377</td>\n",
              "      <td>49.106907</td>\n",
              "      <td>49.090541</td>\n",
              "      <td>49.073285</td>\n",
              "      <td>49.055138</td>\n",
              "      <td>49.036106</td>\n",
              "      <td>49.016190</td>\n",
              "      <td>48.995393</td>\n",
              "      <td>48.973717</td>\n",
              "      <td>48.951167</td>\n",
              "      <td>48.927744</td>\n",
              "      <td>48.903452</td>\n",
              "      <td>48.878294</td>\n",
              "      <td>48.852272</td>\n",
              "      <td>48.825390</td>\n",
              "      <td>48.797651</td>\n",
              "      <td>48.769058</td>\n",
              "      <td>48.739614</td>\n",
              "      <td>48.709323</td>\n",
              "      <td>48.678188</td>\n",
              "      <td>48.646211</td>\n",
              "      <td>48.613397</td>\n",
              "      <td>48.579749</td>\n",
              "      <td>48.545271</td>\n",
              "      <td>48.509965</td>\n",
              "      <td>48.473835</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/left/signal.out15</th>\n",
              "      <td>39.197015</td>\n",
              "      <td>39.025664</td>\n",
              "      <td>38.854437</td>\n",
              "      <td>38.683337</td>\n",
              "      <td>38.512367</td>\n",
              "      <td>38.341531</td>\n",
              "      <td>38.170831</td>\n",
              "      <td>38.000271</td>\n",
              "      <td>37.829854</td>\n",
              "      <td>37.659583</td>\n",
              "      <td>37.489463</td>\n",
              "      <td>37.319495</td>\n",
              "      <td>37.149683</td>\n",
              "      <td>36.980031</td>\n",
              "      <td>36.810541</td>\n",
              "      <td>36.641216</td>\n",
              "      <td>36.472061</td>\n",
              "      <td>36.303077</td>\n",
              "      <td>36.134269</td>\n",
              "      <td>35.965639</td>\n",
              "      <td>35.797190</td>\n",
              "      <td>35.628926</td>\n",
              "      <td>35.460850</td>\n",
              "      <td>35.292964</td>\n",
              "      <td>35.125272</td>\n",
              "      <td>34.957777</td>\n",
              "      <td>34.790482</td>\n",
              "      <td>34.623389</td>\n",
              "      <td>34.456503</td>\n",
              "      <td>34.289826</td>\n",
              "      <td>34.123361</td>\n",
              "      <td>33.957111</td>\n",
              "      <td>33.791078</td>\n",
              "      <td>33.625267</td>\n",
              "      <td>33.459680</td>\n",
              "      <td>33.294319</td>\n",
              "      <td>33.129189</td>\n",
              "      <td>32.964290</td>\n",
              "      <td>32.799628</td>\n",
              "      <td>32.635204</td>\n",
              "      <td>...</td>\n",
              "      <td>45.940113</td>\n",
              "      <td>45.766588</td>\n",
              "      <td>45.593052</td>\n",
              "      <td>45.419510</td>\n",
              "      <td>45.245966</td>\n",
              "      <td>45.072422</td>\n",
              "      <td>44.898882</td>\n",
              "      <td>44.725350</td>\n",
              "      <td>44.551829</td>\n",
              "      <td>44.378323</td>\n",
              "      <td>44.204834</td>\n",
              "      <td>44.031367</td>\n",
              "      <td>43.857926</td>\n",
              "      <td>43.684512</td>\n",
              "      <td>43.511131</td>\n",
              "      <td>43.337785</td>\n",
              "      <td>43.164477</td>\n",
              "      <td>42.991212</td>\n",
              "      <td>42.817993</td>\n",
              "      <td>42.644823</td>\n",
              "      <td>42.471706</td>\n",
              "      <td>42.298645</td>\n",
              "      <td>42.125643</td>\n",
              "      <td>41.952704</td>\n",
              "      <td>41.779831</td>\n",
              "      <td>41.607029</td>\n",
              "      <td>41.434299</td>\n",
              "      <td>41.261646</td>\n",
              "      <td>41.089073</td>\n",
              "      <td>40.916584</td>\n",
              "      <td>40.744181</td>\n",
              "      <td>40.571868</td>\n",
              "      <td>40.399649</td>\n",
              "      <td>40.227527</td>\n",
              "      <td>40.055505</td>\n",
              "      <td>39.883586</td>\n",
              "      <td>39.711775</td>\n",
              "      <td>39.540073</td>\n",
              "      <td>39.368486</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/nothing/signal5 (1).out31</th>\n",
              "      <td>-0.302646</td>\n",
              "      <td>-0.298477</td>\n",
              "      <td>-0.294293</td>\n",
              "      <td>-0.290095</td>\n",
              "      <td>-0.285882</td>\n",
              "      <td>-0.281655</td>\n",
              "      <td>-0.277414</td>\n",
              "      <td>-0.273159</td>\n",
              "      <td>-0.268889</td>\n",
              "      <td>-0.264606</td>\n",
              "      <td>-0.260309</td>\n",
              "      <td>-0.255998</td>\n",
              "      <td>-0.251673</td>\n",
              "      <td>-0.247335</td>\n",
              "      <td>-0.242983</td>\n",
              "      <td>-0.238618</td>\n",
              "      <td>-0.234240</td>\n",
              "      <td>-0.229849</td>\n",
              "      <td>-0.225444</td>\n",
              "      <td>-0.221027</td>\n",
              "      <td>-0.216597</td>\n",
              "      <td>-0.212154</td>\n",
              "      <td>-0.207698</td>\n",
              "      <td>-0.203230</td>\n",
              "      <td>-0.198750</td>\n",
              "      <td>-0.194257</td>\n",
              "      <td>-0.189751</td>\n",
              "      <td>-0.185234</td>\n",
              "      <td>-0.180705</td>\n",
              "      <td>-0.176163</td>\n",
              "      <td>-0.171610</td>\n",
              "      <td>-0.167045</td>\n",
              "      <td>-0.162469</td>\n",
              "      <td>-0.157881</td>\n",
              "      <td>-0.153281</td>\n",
              "      <td>-0.148670</td>\n",
              "      <td>-0.144048</td>\n",
              "      <td>-0.139415</td>\n",
              "      <td>-0.134771</td>\n",
              "      <td>-0.130116</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.452867</td>\n",
              "      <td>-0.449337</td>\n",
              "      <td>-0.445790</td>\n",
              "      <td>-0.442225</td>\n",
              "      <td>-0.438642</td>\n",
              "      <td>-0.435042</td>\n",
              "      <td>-0.431423</td>\n",
              "      <td>-0.427787</td>\n",
              "      <td>-0.424134</td>\n",
              "      <td>-0.420463</td>\n",
              "      <td>-0.416775</td>\n",
              "      <td>-0.413069</td>\n",
              "      <td>-0.409347</td>\n",
              "      <td>-0.405607</td>\n",
              "      <td>-0.401850</td>\n",
              "      <td>-0.398076</td>\n",
              "      <td>-0.394286</td>\n",
              "      <td>-0.390478</td>\n",
              "      <td>-0.386654</td>\n",
              "      <td>-0.382813</td>\n",
              "      <td>-0.378956</td>\n",
              "      <td>-0.375082</td>\n",
              "      <td>-0.371192</td>\n",
              "      <td>-0.367286</td>\n",
              "      <td>-0.363364</td>\n",
              "      <td>-0.359425</td>\n",
              "      <td>-0.355470</td>\n",
              "      <td>-0.351500</td>\n",
              "      <td>-0.347514</td>\n",
              "      <td>-0.343512</td>\n",
              "      <td>-0.339494</td>\n",
              "      <td>-0.335461</td>\n",
              "      <td>-0.331412</td>\n",
              "      <td>-0.327348</td>\n",
              "      <td>-0.323268</td>\n",
              "      <td>-0.319174</td>\n",
              "      <td>-0.315064</td>\n",
              "      <td>-0.310940</td>\n",
              "      <td>-0.306800</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/nothing/signal5 (1).out36</th>\n",
              "      <td>-4.837324</td>\n",
              "      <td>-4.843120</td>\n",
              "      <td>-4.848835</td>\n",
              "      <td>-4.854469</td>\n",
              "      <td>-4.860021</td>\n",
              "      <td>-4.865492</td>\n",
              "      <td>-4.870880</td>\n",
              "      <td>-4.876187</td>\n",
              "      <td>-4.881411</td>\n",
              "      <td>-4.886552</td>\n",
              "      <td>-4.891611</td>\n",
              "      <td>-4.896586</td>\n",
              "      <td>-4.901479</td>\n",
              "      <td>-4.906288</td>\n",
              "      <td>-4.911013</td>\n",
              "      <td>-4.915655</td>\n",
              "      <td>-4.920213</td>\n",
              "      <td>-4.924687</td>\n",
              "      <td>-4.929076</td>\n",
              "      <td>-4.933382</td>\n",
              "      <td>-4.937603</td>\n",
              "      <td>-4.941739</td>\n",
              "      <td>-4.945791</td>\n",
              "      <td>-4.949758</td>\n",
              "      <td>-4.953640</td>\n",
              "      <td>-4.957437</td>\n",
              "      <td>-4.961149</td>\n",
              "      <td>-4.964775</td>\n",
              "      <td>-4.968316</td>\n",
              "      <td>-4.971772</td>\n",
              "      <td>-4.975143</td>\n",
              "      <td>-4.978427</td>\n",
              "      <td>-4.981627</td>\n",
              "      <td>-4.984740</td>\n",
              "      <td>-4.987768</td>\n",
              "      <td>-4.990710</td>\n",
              "      <td>-4.993567</td>\n",
              "      <td>-4.996337</td>\n",
              "      <td>-4.999022</td>\n",
              "      <td>-5.001621</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.551233</td>\n",
              "      <td>-4.559945</td>\n",
              "      <td>-4.568589</td>\n",
              "      <td>-4.577165</td>\n",
              "      <td>-4.585672</td>\n",
              "      <td>-4.594111</td>\n",
              "      <td>-4.602481</td>\n",
              "      <td>-4.610781</td>\n",
              "      <td>-4.619011</td>\n",
              "      <td>-4.627170</td>\n",
              "      <td>-4.635259</td>\n",
              "      <td>-4.643276</td>\n",
              "      <td>-4.651221</td>\n",
              "      <td>-4.659095</td>\n",
              "      <td>-4.666896</td>\n",
              "      <td>-4.674624</td>\n",
              "      <td>-4.682279</td>\n",
              "      <td>-4.689860</td>\n",
              "      <td>-4.697367</td>\n",
              "      <td>-4.704800</td>\n",
              "      <td>-4.712158</td>\n",
              "      <td>-4.719441</td>\n",
              "      <td>-4.726649</td>\n",
              "      <td>-4.733781</td>\n",
              "      <td>-4.740836</td>\n",
              "      <td>-4.747816</td>\n",
              "      <td>-4.754718</td>\n",
              "      <td>-4.761544</td>\n",
              "      <td>-4.768292</td>\n",
              "      <td>-4.774962</td>\n",
              "      <td>-4.781554</td>\n",
              "      <td>-4.788068</td>\n",
              "      <td>-4.794503</td>\n",
              "      <td>-4.800859</td>\n",
              "      <td>-4.807136</td>\n",
              "      <td>-4.813334</td>\n",
              "      <td>-4.819452</td>\n",
              "      <td>-4.825490</td>\n",
              "      <td>-4.831447</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/nothing/signal5 (1).out35</th>\n",
              "      <td>-4.570679</td>\n",
              "      <td>-4.589240</td>\n",
              "      <td>-4.607746</td>\n",
              "      <td>-4.626195</td>\n",
              "      <td>-4.644588</td>\n",
              "      <td>-4.662924</td>\n",
              "      <td>-4.681202</td>\n",
              "      <td>-4.699422</td>\n",
              "      <td>-4.717584</td>\n",
              "      <td>-4.735686</td>\n",
              "      <td>-4.753729</td>\n",
              "      <td>-4.771712</td>\n",
              "      <td>-4.789634</td>\n",
              "      <td>-4.807495</td>\n",
              "      <td>-4.825295</td>\n",
              "      <td>-4.843032</td>\n",
              "      <td>-4.860708</td>\n",
              "      <td>-4.878320</td>\n",
              "      <td>-4.895869</td>\n",
              "      <td>-4.913354</td>\n",
              "      <td>-4.930775</td>\n",
              "      <td>-4.948131</td>\n",
              "      <td>-4.965422</td>\n",
              "      <td>-4.982647</td>\n",
              "      <td>-4.999806</td>\n",
              "      <td>-5.016899</td>\n",
              "      <td>-5.033925</td>\n",
              "      <td>-5.050883</td>\n",
              "      <td>-5.067774</td>\n",
              "      <td>-5.084597</td>\n",
              "      <td>-5.101351</td>\n",
              "      <td>-5.118037</td>\n",
              "      <td>-5.134653</td>\n",
              "      <td>-5.151199</td>\n",
              "      <td>-5.167676</td>\n",
              "      <td>-5.184081</td>\n",
              "      <td>-5.200416</td>\n",
              "      <td>-5.216680</td>\n",
              "      <td>-5.232872</td>\n",
              "      <td>-5.248993</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.809440</td>\n",
              "      <td>-3.829723</td>\n",
              "      <td>-3.849974</td>\n",
              "      <td>-3.870191</td>\n",
              "      <td>-3.890375</td>\n",
              "      <td>-3.910524</td>\n",
              "      <td>-3.930637</td>\n",
              "      <td>-3.950715</td>\n",
              "      <td>-3.970757</td>\n",
              "      <td>-3.990762</td>\n",
              "      <td>-4.010728</td>\n",
              "      <td>-4.030657</td>\n",
              "      <td>-4.050547</td>\n",
              "      <td>-4.070397</td>\n",
              "      <td>-4.090207</td>\n",
              "      <td>-4.109976</td>\n",
              "      <td>-4.129704</td>\n",
              "      <td>-4.149390</td>\n",
              "      <td>-4.169033</td>\n",
              "      <td>-4.188634</td>\n",
              "      <td>-4.208190</td>\n",
              "      <td>-4.227702</td>\n",
              "      <td>-4.247170</td>\n",
              "      <td>-4.266591</td>\n",
              "      <td>-4.285967</td>\n",
              "      <td>-4.305296</td>\n",
              "      <td>-4.324577</td>\n",
              "      <td>-4.343811</td>\n",
              "      <td>-4.362996</td>\n",
              "      <td>-4.382133</td>\n",
              "      <td>-4.401219</td>\n",
              "      <td>-4.420256</td>\n",
              "      <td>-4.439242</td>\n",
              "      <td>-4.458177</td>\n",
              "      <td>-4.477060</td>\n",
              "      <td>-4.495891</td>\n",
              "      <td>-4.514669</td>\n",
              "      <td>-4.533393</td>\n",
              "      <td>-4.552063</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/nothing/signal5 (1).out34</th>\n",
              "      <td>-6.268630</td>\n",
              "      <td>-6.287208</td>\n",
              "      <td>-6.305723</td>\n",
              "      <td>-6.324174</td>\n",
              "      <td>-6.342560</td>\n",
              "      <td>-6.360881</td>\n",
              "      <td>-6.379136</td>\n",
              "      <td>-6.397326</td>\n",
              "      <td>-6.415449</td>\n",
              "      <td>-6.433506</td>\n",
              "      <td>-6.451495</td>\n",
              "      <td>-6.469417</td>\n",
              "      <td>-6.487270</td>\n",
              "      <td>-6.505056</td>\n",
              "      <td>-6.522772</td>\n",
              "      <td>-6.540420</td>\n",
              "      <td>-6.557997</td>\n",
              "      <td>-6.575505</td>\n",
              "      <td>-6.592942</td>\n",
              "      <td>-6.610309</td>\n",
              "      <td>-6.627604</td>\n",
              "      <td>-6.644828</td>\n",
              "      <td>-6.661980</td>\n",
              "      <td>-6.679060</td>\n",
              "      <td>-6.696067</td>\n",
              "      <td>-6.713001</td>\n",
              "      <td>-6.729862</td>\n",
              "      <td>-6.746649</td>\n",
              "      <td>-6.763362</td>\n",
              "      <td>-6.780001</td>\n",
              "      <td>-6.796565</td>\n",
              "      <td>-6.813054</td>\n",
              "      <td>-6.829468</td>\n",
              "      <td>-6.845806</td>\n",
              "      <td>-6.862068</td>\n",
              "      <td>-6.878254</td>\n",
              "      <td>-6.894364</td>\n",
              "      <td>-6.910397</td>\n",
              "      <td>-6.926352</td>\n",
              "      <td>-6.942230</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.499509</td>\n",
              "      <td>-5.520188</td>\n",
              "      <td>-5.540824</td>\n",
              "      <td>-5.561415</td>\n",
              "      <td>-5.581961</td>\n",
              "      <td>-5.602462</td>\n",
              "      <td>-5.622917</td>\n",
              "      <td>-5.643326</td>\n",
              "      <td>-5.663687</td>\n",
              "      <td>-5.684000</td>\n",
              "      <td>-5.704266</td>\n",
              "      <td>-5.724482</td>\n",
              "      <td>-5.744650</td>\n",
              "      <td>-5.764767</td>\n",
              "      <td>-5.784834</td>\n",
              "      <td>-5.804851</td>\n",
              "      <td>-5.824815</td>\n",
              "      <td>-5.844728</td>\n",
              "      <td>-5.864588</td>\n",
              "      <td>-5.884396</td>\n",
              "      <td>-5.904150</td>\n",
              "      <td>-5.923849</td>\n",
              "      <td>-5.943494</td>\n",
              "      <td>-5.963084</td>\n",
              "      <td>-5.982619</td>\n",
              "      <td>-6.002097</td>\n",
              "      <td>-6.021519</td>\n",
              "      <td>-6.040884</td>\n",
              "      <td>-6.060191</td>\n",
              "      <td>-6.079440</td>\n",
              "      <td>-6.098630</td>\n",
              "      <td>-6.117762</td>\n",
              "      <td>-6.136834</td>\n",
              "      <td>-6.155845</td>\n",
              "      <td>-6.174797</td>\n",
              "      <td>-6.193687</td>\n",
              "      <td>-6.212516</td>\n",
              "      <td>-6.231283</td>\n",
              "      <td>-6.249988</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/nothing/signal5 (1).out32</th>\n",
              "      <td>-0.301777</td>\n",
              "      <td>-0.299847</td>\n",
              "      <td>-0.297909</td>\n",
              "      <td>-0.295961</td>\n",
              "      <td>-0.294006</td>\n",
              "      <td>-0.292041</td>\n",
              "      <td>-0.290068</td>\n",
              "      <td>-0.288087</td>\n",
              "      <td>-0.286097</td>\n",
              "      <td>-0.284098</td>\n",
              "      <td>-0.282091</td>\n",
              "      <td>-0.280076</td>\n",
              "      <td>-0.278051</td>\n",
              "      <td>-0.276019</td>\n",
              "      <td>-0.273977</td>\n",
              "      <td>-0.271927</td>\n",
              "      <td>-0.269869</td>\n",
              "      <td>-0.267802</td>\n",
              "      <td>-0.265726</td>\n",
              "      <td>-0.263642</td>\n",
              "      <td>-0.261550</td>\n",
              "      <td>-0.259449</td>\n",
              "      <td>-0.257339</td>\n",
              "      <td>-0.255221</td>\n",
              "      <td>-0.253094</td>\n",
              "      <td>-0.250959</td>\n",
              "      <td>-0.248815</td>\n",
              "      <td>-0.246663</td>\n",
              "      <td>-0.244502</td>\n",
              "      <td>-0.242333</td>\n",
              "      <td>-0.240155</td>\n",
              "      <td>-0.237969</td>\n",
              "      <td>-0.235774</td>\n",
              "      <td>-0.233571</td>\n",
              "      <td>-0.231360</td>\n",
              "      <td>-0.229140</td>\n",
              "      <td>-0.226911</td>\n",
              "      <td>-0.224675</td>\n",
              "      <td>-0.222429</td>\n",
              "      <td>-0.220176</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.370492</td>\n",
              "      <td>-0.368886</td>\n",
              "      <td>-0.367273</td>\n",
              "      <td>-0.365651</td>\n",
              "      <td>-0.364022</td>\n",
              "      <td>-0.362384</td>\n",
              "      <td>-0.360738</td>\n",
              "      <td>-0.359084</td>\n",
              "      <td>-0.357422</td>\n",
              "      <td>-0.355752</td>\n",
              "      <td>-0.354074</td>\n",
              "      <td>-0.352387</td>\n",
              "      <td>-0.350693</td>\n",
              "      <td>-0.348990</td>\n",
              "      <td>-0.347278</td>\n",
              "      <td>-0.345559</td>\n",
              "      <td>-0.343831</td>\n",
              "      <td>-0.342095</td>\n",
              "      <td>-0.340351</td>\n",
              "      <td>-0.338598</td>\n",
              "      <td>-0.336837</td>\n",
              "      <td>-0.335068</td>\n",
              "      <td>-0.333290</td>\n",
              "      <td>-0.331504</td>\n",
              "      <td>-0.329709</td>\n",
              "      <td>-0.327906</td>\n",
              "      <td>-0.326095</td>\n",
              "      <td>-0.324275</td>\n",
              "      <td>-0.322447</td>\n",
              "      <td>-0.320611</td>\n",
              "      <td>-0.318765</td>\n",
              "      <td>-0.316912</td>\n",
              "      <td>-0.315050</td>\n",
              "      <td>-0.313179</td>\n",
              "      <td>-0.311300</td>\n",
              "      <td>-0.309413</td>\n",
              "      <td>-0.307517</td>\n",
              "      <td>-0.305612</td>\n",
              "      <td>-0.303699</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>232 rows × 9991 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              0          1  ...       9989  class\n",
              "FT_samples/left/signal.out105         -0.138383  -0.273093  ...   0.132445      0\n",
              "FT_samples/left/signal.out13         -15.727242 -15.693789  ... -15.760942      0\n",
              "FT_samples/left/signal.out178          9.991873   9.988105  ...   9.999384      0\n",
              "FT_samples/left/signal.out106         48.399120  48.360541  ...  48.473835      0\n",
              "FT_samples/left/signal.out15          39.197015  39.025664  ...  39.368486      0\n",
              "...                                         ...        ...  ...        ...    ...\n",
              "FT_samples/nothing/signal5 (1).out31  -0.302646  -0.298477  ...  -0.306800      2\n",
              "FT_samples/nothing/signal5 (1).out36  -4.837324  -4.843120  ...  -4.831447      2\n",
              "FT_samples/nothing/signal5 (1).out35  -4.570679  -4.589240  ...  -4.552063      2\n",
              "FT_samples/nothing/signal5 (1).out34  -6.268630  -6.287208  ...  -6.249988      2\n",
              "FT_samples/nothing/signal5 (1).out32  -0.301777  -0.299847  ...  -0.303699      2\n",
              "\n",
              "[232 rows x 9991 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJkdU4rhD1Wt"
      },
      "source": [
        "\n",
        "X_raw = raw_samples.drop([\"class\"], axis = 1)\n",
        "y_raw = raw_samples[\"class\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZrK38mDFXeH"
      },
      "source": [
        "parameters = {'bootstrap': True,\n",
        "              'min_samples_leaf': 3,\n",
        "              'n_estimators': 10000, \n",
        "              'min_samples_split': 10,\n",
        "              'max_features': 'sqrt',\n",
        "              'max_depth': 8,\n",
        "              'max_leaf_nodes': None}\n",
        "\n",
        "RF_model = RandomForestClassifier(**parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jctC_vRPDeYT",
        "outputId": "42098ba7-002f-41bd-d187-389810e5a6f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "cv_steps = 20\n",
        "\n",
        "raw_acc_array = np.empty(cv_steps)\n",
        "\n",
        "for i in range(cv_steps):\n",
        "    print(\"cv\", i + 1, \"of\", cv_steps)\n",
        "    train_X, test_X, train_y, test_y = train_test_split(X_raw, y_raw, test_size=0.1, random_state=i, shuffle = True)\n",
        "    \n",
        "    RF_model.fit(train_X, train_y)\n",
        "    \n",
        "    RF_predictions = RF_model.predict(test_X)\n",
        "    acc_score = accuracy_score(test_y ,RF_predictions)\n",
        "    print(acc_score)\n",
        "\n",
        "    raw_acc_array[i] = acc_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv 1 of 20\n",
            "0.75\n",
            "cv 2 of 20\n",
            "0.6666666666666666\n",
            "cv 3 of 20\n",
            "0.7083333333333334\n",
            "cv 4 of 20\n",
            "0.6666666666666666\n",
            "cv 5 of 20\n",
            "0.8333333333333334\n",
            "cv 6 of 20\n",
            "0.6666666666666666\n",
            "cv 7 of 20\n",
            "0.75\n",
            "cv 8 of 20\n",
            "0.5833333333333334\n",
            "cv 9 of 20\n",
            "0.5416666666666666\n",
            "cv 10 of 20\n",
            "0.5833333333333334\n",
            "cv 11 of 20\n",
            "0.75\n",
            "cv 12 of 20\n",
            "0.75\n",
            "cv 13 of 20\n",
            "0.6666666666666666\n",
            "cv 14 of 20\n",
            "0.7916666666666666\n",
            "cv 15 of 20\n",
            "0.7083333333333334\n",
            "cv 16 of 20\n",
            "0.8333333333333334\n",
            "cv 17 of 20\n",
            "0.75\n",
            "cv 18 of 20\n",
            "0.7083333333333334\n",
            "cv 19 of 20\n",
            "0.625\n",
            "cv 20 of 20\n",
            "0.7916666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjV5hQT4C3YO",
        "outputId": "96e90f28-0386-4c77-f315-c88bf4bce7f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "#@title Code - Minimal Feature Extraction\n",
        "minimal_features  = pd.read_csv(\"Minimal_features.txt\", index_col = 0)\n",
        "minimal_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>value__minimum</th>\n",
              "      <th>value__mean</th>\n",
              "      <th>value__sum_values</th>\n",
              "      <th>value__standard_deviation</th>\n",
              "      <th>value__variance</th>\n",
              "      <th>value__maximum</th>\n",
              "      <th>value__median</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>FT_samples/left/signal.out105</th>\n",
              "      <td>-24.700601</td>\n",
              "      <td>4.401402</td>\n",
              "      <td>43970.003204</td>\n",
              "      <td>28.503879</td>\n",
              "      <td>812.471117</td>\n",
              "      <td>117.805846</td>\n",
              "      <td>-4.374364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/left/signal.out106</th>\n",
              "      <td>-25.773813</td>\n",
              "      <td>7.649105</td>\n",
              "      <td>76414.563114</td>\n",
              "      <td>29.193047</td>\n",
              "      <td>852.233975</td>\n",
              "      <td>117.810076</td>\n",
              "      <td>-3.349600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/left/signal.out13</th>\n",
              "      <td>-36.809364</td>\n",
              "      <td>-6.112428</td>\n",
              "      <td>-61063.151141</td>\n",
              "      <td>8.830963</td>\n",
              "      <td>77.985906</td>\n",
              "      <td>1.448130</td>\n",
              "      <td>-3.076705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/left/signal.out14</th>\n",
              "      <td>-36.075002</td>\n",
              "      <td>-4.846627</td>\n",
              "      <td>-48417.804058</td>\n",
              "      <td>9.165379</td>\n",
              "      <td>84.004177</td>\n",
              "      <td>16.249690</td>\n",
              "      <td>-1.980599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/left/signal.out15</th>\n",
              "      <td>-36.075002</td>\n",
              "      <td>4.513028</td>\n",
              "      <td>45085.146126</td>\n",
              "      <td>23.977513</td>\n",
              "      <td>574.921120</td>\n",
              "      <td>87.543441</td>\n",
              "      <td>-0.340329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/right/signal5 (1).out71</th>\n",
              "      <td>-9.480906</td>\n",
              "      <td>4.287666</td>\n",
              "      <td>42833.781579</td>\n",
              "      <td>10.986216</td>\n",
              "      <td>120.696939</td>\n",
              "      <td>35.028874</td>\n",
              "      <td>-1.497082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/right/signal5 (1).out72</th>\n",
              "      <td>-9.480906</td>\n",
              "      <td>4.564550</td>\n",
              "      <td>45599.857737</td>\n",
              "      <td>10.727971</td>\n",
              "      <td>115.089364</td>\n",
              "      <td>35.028874</td>\n",
              "      <td>-0.970918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/right/signal5 (1).out73</th>\n",
              "      <td>-9.480809</td>\n",
              "      <td>4.719019</td>\n",
              "      <td>47142.995068</td>\n",
              "      <td>10.590190</td>\n",
              "      <td>112.152122</td>\n",
              "      <td>35.028874</td>\n",
              "      <td>0.089503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/right/signal5 (1).out74</th>\n",
              "      <td>-8.414519</td>\n",
              "      <td>4.823562</td>\n",
              "      <td>48187.380837</td>\n",
              "      <td>10.387149</td>\n",
              "      <td>107.892867</td>\n",
              "      <td>35.028874</td>\n",
              "      <td>-0.446639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/right/signal5 (1).out75</th>\n",
              "      <td>-3.977984</td>\n",
              "      <td>5.354665</td>\n",
              "      <td>53493.099945</td>\n",
              "      <td>9.986198</td>\n",
              "      <td>99.724145</td>\n",
              "      <td>35.028874</td>\n",
              "      <td>0.054881</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>232 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    value__minimum  ...  value__median\n",
              "id                                                  ...               \n",
              "FT_samples/left/signal.out105           -24.700601  ...      -4.374364\n",
              "FT_samples/left/signal.out106           -25.773813  ...      -3.349600\n",
              "FT_samples/left/signal.out13            -36.809364  ...      -3.076705\n",
              "FT_samples/left/signal.out14            -36.075002  ...      -1.980599\n",
              "FT_samples/left/signal.out15            -36.075002  ...      -0.340329\n",
              "...                                            ...  ...            ...\n",
              "FT_samples/right/signal5 (1).out71       -9.480906  ...      -1.497082\n",
              "FT_samples/right/signal5 (1).out72       -9.480906  ...      -0.970918\n",
              "FT_samples/right/signal5 (1).out73       -9.480809  ...       0.089503\n",
              "FT_samples/right/signal5 (1).out74       -8.414519  ...      -0.446639\n",
              "FT_samples/right/signal5 (1).out75       -3.977984  ...       0.054881\n",
              "\n",
              "[232 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arAUdxDAGxKh",
        "outputId": "3edfeb69-8ef4-478b-a71d-29318941afc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "cv_steps = 20\n",
        "\n",
        "min_acc_array = np.empty(cv_steps)\n",
        "\n",
        "for i in range(cv_steps):\n",
        "    print(\"cv\", i + 1, \"of\", cv_steps)\n",
        "    train_X, test_X, train_y, test_y = train_test_split(minimal_features, y_raw, test_size=0.1, random_state=i, shuffle = True)\n",
        "    \n",
        "    RF_model.fit(train_X, train_y)\n",
        "    \n",
        "    RF_predictions = RF_model.predict(test_X)\n",
        "    acc_score = accuracy_score(test_y ,RF_predictions)\n",
        "    print(acc_score)\n",
        "\n",
        "    min_acc_array[i] = acc_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv 1 of 20\n",
            "0.9166666666666666\n",
            "cv 2 of 20\n",
            "0.875\n",
            "cv 3 of 20\n",
            "0.9166666666666666\n",
            "cv 4 of 20\n",
            "0.875\n",
            "cv 5 of 20\n",
            "0.8333333333333334\n",
            "cv 6 of 20\n",
            "0.9166666666666666\n",
            "cv 7 of 20\n",
            "0.875\n",
            "cv 8 of 20\n",
            "0.875\n",
            "cv 9 of 20\n",
            "0.7916666666666666\n",
            "cv 10 of 20\n",
            "0.6666666666666666\n",
            "cv 11 of 20\n",
            "0.9166666666666666\n",
            "cv 12 of 20\n",
            "0.9583333333333334\n",
            "cv 13 of 20\n",
            "0.9583333333333334\n",
            "cv 14 of 20\n",
            "0.9166666666666666\n",
            "cv 15 of 20\n",
            "0.9583333333333334\n",
            "cv 16 of 20\n",
            "0.9583333333333334\n",
            "cv 17 of 20\n",
            "0.8333333333333334\n",
            "cv 18 of 20\n",
            "0.875\n",
            "cv 19 of 20\n",
            "0.7916666666666666\n",
            "cv 20 of 20\n",
            "0.8333333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjz8_IbPnVag",
        "outputId": "74801ab9-9eba-4ef4-aef3-7bbfc01a9af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "#@title Code - Efficient Feature Extraction\n",
        "efficient_features  = pd.read_csv(\"Efficient_features.txt\", index_col = 0)\n",
        "efficient_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.0</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.0</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.2__ql_0.0</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.2__ql_0.0</th>\n",
              "      <th>value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.2__ql_0.0</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.0</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.6__ql_0.0</th>\n",
              "      <th>value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.0</th>\n",
              "      <th>value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.6__ql_0.0</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.2</th>\n",
              "      <th>value__minimum</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.2</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.8__ql_0.0</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.2</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.0</th>\n",
              "      <th>value__quantile__q_0.1</th>\n",
              "      <th>value__skewness</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.6__ql_0.2</th>\n",
              "      <th>value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.8__ql_0.0</th>\n",
              "      <th>value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.6__ql_0.2</th>\n",
              "      <th>value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.2</th>\n",
              "      <th>value__c3__lag_3</th>\n",
              "      <th>value__c3__lag_2</th>\n",
              "      <th>value__c3__lag_1</th>\n",
              "      <th>value__longest_strike_above_mean</th>\n",
              "      <th>value__count_below_mean</th>\n",
              "      <th>value__count_above_mean</th>\n",
              "      <th>value__fft_coefficient__coeff_7__attr_\"abs\"</th>\n",
              "      <th>value__fft_coefficient__coeff_80__attr_\"abs\"</th>\n",
              "      <th>value__fft_coefficient__coeff_68__attr_\"abs\"</th>\n",
              "      <th>value__fft_coefficient__coeff_6__attr_\"abs\"</th>\n",
              "      <th>value__quantile__q_0.2</th>\n",
              "      <th>value__augmented_dickey_fuller__attr_\"teststat\"</th>\n",
              "      <th>value__augmented_dickey_fuller__attr_\"pvalue\"</th>\n",
              "      <th>value__mean</th>\n",
              "      <th>value__sum_values</th>\n",
              "      <th>value__fft_coefficient__coeff_0__attr_\"real\"</th>\n",
              "      <th>value__fft_coefficient__coeff_98__attr_\"abs\"</th>\n",
              "      <th>value__fft_coefficient__coeff_13__attr_\"abs\"</th>\n",
              "      <th>value__agg_linear_trend__f_agg_\"var\"__chunk_len_50__attr_\"stderr\"</th>\n",
              "      <th>...</th>\n",
              "      <th>value__number_peaks__n_3</th>\n",
              "      <th>value__change_quantiles__f_agg_\"mean\"__isabs_False__qh_1.0__ql_0.2</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.4</th>\n",
              "      <th>value__fft_coefficient__coeff_15__attr_\"abs\"</th>\n",
              "      <th>value__quantile__q_0.7</th>\n",
              "      <th>value__symmetry_looking__r_0.05</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.4</th>\n",
              "      <th>value__fft_coefficient__coeff_18__attr_\"abs\"</th>\n",
              "      <th>value__partial_autocorrelation__lag_9</th>\n",
              "      <th>value__energy_ratio_by_chunks__num_segments_10__segment_focus_9</th>\n",
              "      <th>value__partial_autocorrelation__lag_6</th>\n",
              "      <th>value__partial_autocorrelation__lag_8</th>\n",
              "      <th>value__partial_autocorrelation__lag_7</th>\n",
              "      <th>value__cid_ce__normalize_True</th>\n",
              "      <th>value__number_crossing_m__m_-1</th>\n",
              "      <th>value__fft_coefficient__coeff_20__attr_\"abs\"</th>\n",
              "      <th>value__agg_autocorrelation__f_agg_\"mean\"__maxlag_40</th>\n",
              "      <th>value__agg_autocorrelation__f_agg_\"median\"__maxlag_40</th>\n",
              "      <th>value__agg_linear_trend__f_agg_\"var\"__chunk_len_50__attr_\"intercept\"</th>\n",
              "      <th>value__agg_linear_trend__f_agg_\"var\"__chunk_len_5__attr_\"intercept\"</th>\n",
              "      <th>value__agg_linear_trend__f_agg_\"var\"__chunk_len_10__attr_\"intercept\"</th>\n",
              "      <th>value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.2</th>\n",
              "      <th>value__autocorrelation__lag_9</th>\n",
              "      <th>value__max_langevin_fixed_point__m_3__r_30</th>\n",
              "      <th>value__autocorrelation__lag_8</th>\n",
              "      <th>value__fft_coefficient__coeff_26__attr_\"abs\"</th>\n",
              "      <th>value__autocorrelation__lag_7</th>\n",
              "      <th>value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.8__ql_0.4</th>\n",
              "      <th>value__autocorrelation__lag_6</th>\n",
              "      <th>value__fft_aggregated__aggtype_\"kurtosis\"</th>\n",
              "      <th>value__autocorrelation__lag_5</th>\n",
              "      <th>value__autocorrelation__lag_4</th>\n",
              "      <th>value__autocorrelation__lag_3</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.4</th>\n",
              "      <th>value__autocorrelation__lag_2</th>\n",
              "      <th>value__fft_aggregated__aggtype_\"skew\"</th>\n",
              "      <th>value__autocorrelation__lag_1</th>\n",
              "      <th>value__partial_autocorrelation__lag_1</th>\n",
              "      <th>value__fft_coefficient__coeff_27__attr_\"abs\"</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.8__ql_0.4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>FT_samples/left/signal.out105</th>\n",
              "      <td>0.000391</td>\n",
              "      <td>0.000420</td>\n",
              "      <td>0.000930</td>\n",
              "      <td>0.000547</td>\n",
              "      <td>0.019558</td>\n",
              "      <td>0.000547</td>\n",
              "      <td>0.000588</td>\n",
              "      <td>0.012524</td>\n",
              "      <td>0.012969</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>-24.700601</td>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000640</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.000466</td>\n",
              "      <td>-9.468686</td>\n",
              "      <td>2.726326</td>\n",
              "      <td>0.000414</td>\n",
              "      <td>0.013200</td>\n",
              "      <td>0.009646</td>\n",
              "      <td>0.005413</td>\n",
              "      <td>73978.840087</td>\n",
              "      <td>73968.048263</td>\n",
              "      <td>73955.651299</td>\n",
              "      <td>1288.0</td>\n",
              "      <td>8101.0</td>\n",
              "      <td>1889.0</td>\n",
              "      <td>33847.828027</td>\n",
              "      <td>2.700682e+00</td>\n",
              "      <td>3.181434e+00</td>\n",
              "      <td>53045.134294</td>\n",
              "      <td>-8.102004</td>\n",
              "      <td>0.010290</td>\n",
              "      <td>0.959375</td>\n",
              "      <td>4.401402</td>\n",
              "      <td>43970.003204</td>\n",
              "      <td>43970.003204</td>\n",
              "      <td>2.202234e+00</td>\n",
              "      <td>2808.303234</td>\n",
              "      <td>0.003150</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.498692e-05</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>2156.444669</td>\n",
              "      <td>1.832249</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005742</td>\n",
              "      <td>655.680868</td>\n",
              "      <td>0.043223</td>\n",
              "      <td>0.862502</td>\n",
              "      <td>0.038294</td>\n",
              "      <td>0.041444</td>\n",
              "      <td>0.039807</td>\n",
              "      <td>0.250793</td>\n",
              "      <td>6.0</td>\n",
              "      <td>304.389956</td>\n",
              "      <td>1.000269</td>\n",
              "      <td>1.000448</td>\n",
              "      <td>-1.222426</td>\n",
              "      <td>-0.011974</td>\n",
              "      <td>-0.049346</td>\n",
              "      <td>0.038285</td>\n",
              "      <td>1.000625</td>\n",
              "      <td>127.711997</td>\n",
              "      <td>1.000581</td>\n",
              "      <td>32.563949</td>\n",
              "      <td>1.000530</td>\n",
              "      <td>0.013844</td>\n",
              "      <td>1.000473</td>\n",
              "      <td>2511.849282</td>\n",
              "      <td>1.000410</td>\n",
              "      <td>1.000341</td>\n",
              "      <td>1.000265</td>\n",
              "      <td>0.000538</td>\n",
              "      <td>1.000183</td>\n",
              "      <td>47.541878</td>\n",
              "      <td>1.000095</td>\n",
              "      <td>1.000095</td>\n",
              "      <td>19.219994</td>\n",
              "      <td>0.000730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/left/signal.out106</th>\n",
              "      <td>0.000818</td>\n",
              "      <td>0.000824</td>\n",
              "      <td>0.001754</td>\n",
              "      <td>0.001256</td>\n",
              "      <td>0.022305</td>\n",
              "      <td>0.001010</td>\n",
              "      <td>0.001024</td>\n",
              "      <td>0.013823</td>\n",
              "      <td>0.014138</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>-25.773813</td>\n",
              "      <td>0.000551</td>\n",
              "      <td>0.001551</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.001240</td>\n",
              "      <td>-8.918993</td>\n",
              "      <td>2.337296</td>\n",
              "      <td>0.000651</td>\n",
              "      <td>0.017623</td>\n",
              "      <td>0.010007</td>\n",
              "      <td>0.005227</td>\n",
              "      <td>78116.324078</td>\n",
              "      <td>78127.840637</td>\n",
              "      <td>78137.594734</td>\n",
              "      <td>1216.0</td>\n",
              "      <td>7737.0</td>\n",
              "      <td>2253.0</td>\n",
              "      <td>56680.854601</td>\n",
              "      <td>8.389797e-01</td>\n",
              "      <td>1.029707e+00</td>\n",
              "      <td>77325.248880</td>\n",
              "      <td>-7.662665</td>\n",
              "      <td>-0.024825</td>\n",
              "      <td>0.956430</td>\n",
              "      <td>7.649105</td>\n",
              "      <td>76414.563114</td>\n",
              "      <td>76414.563114</td>\n",
              "      <td>6.589533e-01</td>\n",
              "      <td>5965.472758</td>\n",
              "      <td>0.003334</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.114405e-05</td>\n",
              "      <td>0.010159</td>\n",
              "      <td>2321.315005</td>\n",
              "      <td>3.039637</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006321</td>\n",
              "      <td>1367.284796</td>\n",
              "      <td>-0.030235</td>\n",
              "      <td>0.082327</td>\n",
              "      <td>-0.033332</td>\n",
              "      <td>-0.031203</td>\n",
              "      <td>-0.032233</td>\n",
              "      <td>0.276014</td>\n",
              "      <td>6.0</td>\n",
              "      <td>303.562854</td>\n",
              "      <td>0.995950</td>\n",
              "      <td>0.996449</td>\n",
              "      <td>-1.159762</td>\n",
              "      <td>-0.011340</td>\n",
              "      <td>-0.046724</td>\n",
              "      <td>0.047812</td>\n",
              "      <td>0.998834</td>\n",
              "      <td>123.356237</td>\n",
              "      <td>0.998994</td>\n",
              "      <td>39.537542</td>\n",
              "      <td>0.999146</td>\n",
              "      <td>0.021362</td>\n",
              "      <td>0.999291</td>\n",
              "      <td>9705.505772</td>\n",
              "      <td>0.999428</td>\n",
              "      <td>0.999558</td>\n",
              "      <td>0.999680</td>\n",
              "      <td>0.001627</td>\n",
              "      <td>0.999794</td>\n",
              "      <td>93.155437</td>\n",
              "      <td>0.999901</td>\n",
              "      <td>0.999901</td>\n",
              "      <td>26.802479</td>\n",
              "      <td>0.002083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/left/signal.out13</th>\n",
              "      <td>0.000406</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>0.001354</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>0.029087</td>\n",
              "      <td>0.000766</td>\n",
              "      <td>0.000546</td>\n",
              "      <td>0.018957</td>\n",
              "      <td>0.015538</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>-36.809364</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.000416</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>-15.676982</td>\n",
              "      <td>-1.928230</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.012747</td>\n",
              "      <td>0.008754</td>\n",
              "      <td>0.008802</td>\n",
              "      <td>-2985.447698</td>\n",
              "      <td>-2985.729827</td>\n",
              "      <td>-2985.972392</td>\n",
              "      <td>6851.0</td>\n",
              "      <td>3139.0</td>\n",
              "      <td>6851.0</td>\n",
              "      <td>8848.352986</td>\n",
              "      <td>3.959296e-13</td>\n",
              "      <td>6.908439e-13</td>\n",
              "      <td>12434.703474</td>\n",
              "      <td>-10.090990</td>\n",
              "      <td>-0.125357</td>\n",
              "      <td>0.946854</td>\n",
              "      <td>-6.112428</td>\n",
              "      <td>-61063.151141</td>\n",
              "      <td>-61063.151141</td>\n",
              "      <td>2.387824e-13</td>\n",
              "      <td>1325.458079</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-4.189207e-07</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>706.626272</td>\n",
              "      <td>-0.357945</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>338.919889</td>\n",
              "      <td>-0.060293</td>\n",
              "      <td>0.728272</td>\n",
              "      <td>-0.073049</td>\n",
              "      <td>-0.064003</td>\n",
              "      <td>-0.068218</td>\n",
              "      <td>0.207549</td>\n",
              "      <td>6.0</td>\n",
              "      <td>89.285477</td>\n",
              "      <td>0.998401</td>\n",
              "      <td>0.998695</td>\n",
              "      <td>-0.072839</td>\n",
              "      <td>-0.000714</td>\n",
              "      <td>-0.002942</td>\n",
              "      <td>0.006386</td>\n",
              "      <td>0.999654</td>\n",
              "      <td>-1.590232</td>\n",
              "      <td>0.999710</td>\n",
              "      <td>7.175242</td>\n",
              "      <td>0.999761</td>\n",
              "      <td>0.006531</td>\n",
              "      <td>0.999808</td>\n",
              "      <td>7.972018</td>\n",
              "      <td>0.999851</td>\n",
              "      <td>0.999890</td>\n",
              "      <td>0.999924</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.999953</td>\n",
              "      <td>1.568670</td>\n",
              "      <td>0.999979</td>\n",
              "      <td>0.999979</td>\n",
              "      <td>2.668712</td>\n",
              "      <td>0.000067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/left/signal.out14</th>\n",
              "      <td>0.000932</td>\n",
              "      <td>0.000758</td>\n",
              "      <td>0.002579</td>\n",
              "      <td>0.001004</td>\n",
              "      <td>0.039684</td>\n",
              "      <td>0.001612</td>\n",
              "      <td>0.001217</td>\n",
              "      <td>0.026073</td>\n",
              "      <td>0.021419</td>\n",
              "      <td>0.000482</td>\n",
              "      <td>-36.075002</td>\n",
              "      <td>0.000381</td>\n",
              "      <td>0.000952</td>\n",
              "      <td>0.000635</td>\n",
              "      <td>0.000649</td>\n",
              "      <td>-18.389842</td>\n",
              "      <td>-1.480259</td>\n",
              "      <td>0.000531</td>\n",
              "      <td>0.017404</td>\n",
              "      <td>0.012243</td>\n",
              "      <td>0.012365</td>\n",
              "      <td>-2472.441504</td>\n",
              "      <td>-2473.276748</td>\n",
              "      <td>-2474.056930</td>\n",
              "      <td>3655.0</td>\n",
              "      <td>2986.0</td>\n",
              "      <td>7004.0</td>\n",
              "      <td>22143.945886</td>\n",
              "      <td>1.579581e-12</td>\n",
              "      <td>1.588101e-12</td>\n",
              "      <td>27402.765636</td>\n",
              "      <td>-8.647223</td>\n",
              "      <td>-0.003461</td>\n",
              "      <td>0.958245</td>\n",
              "      <td>-4.846627</td>\n",
              "      <td>-48417.804058</td>\n",
              "      <td>-48417.804058</td>\n",
              "      <td>2.144059e-13</td>\n",
              "      <td>2478.855410</td>\n",
              "      <td>0.000639</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-1.807235e-06</td>\n",
              "      <td>0.000624</td>\n",
              "      <td>1506.780830</td>\n",
              "      <td>-0.192095</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000481</td>\n",
              "      <td>646.885020</td>\n",
              "      <td>-0.038403</td>\n",
              "      <td>0.208980</td>\n",
              "      <td>-0.043372</td>\n",
              "      <td>-0.039928</td>\n",
              "      <td>-0.041578</td>\n",
              "      <td>0.348384</td>\n",
              "      <td>8.0</td>\n",
              "      <td>195.743227</td>\n",
              "      <td>0.994379</td>\n",
              "      <td>0.995184</td>\n",
              "      <td>-0.230482</td>\n",
              "      <td>-0.002252</td>\n",
              "      <td>-0.009280</td>\n",
              "      <td>0.012062</td>\n",
              "      <td>0.998516</td>\n",
              "      <td>-6.123410</td>\n",
              "      <td>0.998729</td>\n",
              "      <td>11.505571</td>\n",
              "      <td>0.998931</td>\n",
              "      <td>0.008687</td>\n",
              "      <td>0.999120</td>\n",
              "      <td>10.134966</td>\n",
              "      <td>0.999297</td>\n",
              "      <td>0.999462</td>\n",
              "      <td>0.999615</td>\n",
              "      <td>0.000211</td>\n",
              "      <td>0.999755</td>\n",
              "      <td>0.795693</td>\n",
              "      <td>0.999884</td>\n",
              "      <td>0.999884</td>\n",
              "      <td>2.236141</td>\n",
              "      <td>0.000286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/left/signal.out15</th>\n",
              "      <td>0.000992</td>\n",
              "      <td>0.000835</td>\n",
              "      <td>0.002962</td>\n",
              "      <td>0.001226</td>\n",
              "      <td>0.041664</td>\n",
              "      <td>0.001774</td>\n",
              "      <td>0.001273</td>\n",
              "      <td>0.027976</td>\n",
              "      <td>0.020922</td>\n",
              "      <td>0.000373</td>\n",
              "      <td>-36.075002</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.001021</td>\n",
              "      <td>0.000574</td>\n",
              "      <td>0.000723</td>\n",
              "      <td>-10.632315</td>\n",
              "      <td>2.039117</td>\n",
              "      <td>0.000422</td>\n",
              "      <td>0.017245</td>\n",
              "      <td>0.010493</td>\n",
              "      <td>0.014175</td>\n",
              "      <td>35963.835421</td>\n",
              "      <td>35970.192881</td>\n",
              "      <td>35975.979818</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>8175.0</td>\n",
              "      <td>1815.0</td>\n",
              "      <td>46005.862089</td>\n",
              "      <td>1.795838e-12</td>\n",
              "      <td>2.402651e-12</td>\n",
              "      <td>50714.513704</td>\n",
              "      <td>-4.147070</td>\n",
              "      <td>0.010918</td>\n",
              "      <td>0.959426</td>\n",
              "      <td>4.513028</td>\n",
              "      <td>45085.146126</td>\n",
              "      <td>45085.146126</td>\n",
              "      <td>2.088917e-13</td>\n",
              "      <td>3843.420282</td>\n",
              "      <td>0.001765</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.069830e-05</td>\n",
              "      <td>0.004659</td>\n",
              "      <td>701.153805</td>\n",
              "      <td>0.636109</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.003213</td>\n",
              "      <td>1064.703292</td>\n",
              "      <td>-0.022716</td>\n",
              "      <td>0.833571</td>\n",
              "      <td>-0.024390</td>\n",
              "      <td>-0.023249</td>\n",
              "      <td>-0.023806</td>\n",
              "      <td>0.246798</td>\n",
              "      <td>10.0</td>\n",
              "      <td>189.853863</td>\n",
              "      <td>0.996050</td>\n",
              "      <td>0.996453</td>\n",
              "      <td>-0.376067</td>\n",
              "      <td>-0.003793</td>\n",
              "      <td>-0.015624</td>\n",
              "      <td>0.032088</td>\n",
              "      <td>0.998759</td>\n",
              "      <td>193.222891</td>\n",
              "      <td>0.998921</td>\n",
              "      <td>20.772629</td>\n",
              "      <td>0.999077</td>\n",
              "      <td>0.006448</td>\n",
              "      <td>0.999228</td>\n",
              "      <td>12.893898</td>\n",
              "      <td>0.999372</td>\n",
              "      <td>0.999509</td>\n",
              "      <td>0.999641</td>\n",
              "      <td>0.000218</td>\n",
              "      <td>0.999767</td>\n",
              "      <td>1.257082</td>\n",
              "      <td>0.999887</td>\n",
              "      <td>0.999887</td>\n",
              "      <td>9.282798</td>\n",
              "      <td>0.000260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/right/signal5 (1).out71</th>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000232</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.012847</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>0.008695</td>\n",
              "      <td>0.006926</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>-9.480906</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000238</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000133</td>\n",
              "      <td>-5.050037</td>\n",
              "      <td>1.142372</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.010236</td>\n",
              "      <td>0.003968</td>\n",
              "      <td>0.004541</td>\n",
              "      <td>3146.579727</td>\n",
              "      <td>3146.390221</td>\n",
              "      <td>3146.167135</td>\n",
              "      <td>3141.0</td>\n",
              "      <td>6629.0</td>\n",
              "      <td>3361.0</td>\n",
              "      <td>10813.939780</td>\n",
              "      <td>2.039574e-13</td>\n",
              "      <td>3.291805e-13</td>\n",
              "      <td>8145.580697</td>\n",
              "      <td>-2.727483</td>\n",
              "      <td>-0.078060</td>\n",
              "      <td>0.951580</td>\n",
              "      <td>4.287666</td>\n",
              "      <td>42833.781579</td>\n",
              "      <td>42833.781579</td>\n",
              "      <td>3.140637e-13</td>\n",
              "      <td>1117.327112</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.101192e-06</td>\n",
              "      <td>0.000568</td>\n",
              "      <td>698.144473</td>\n",
              "      <td>10.276868</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>910.576911</td>\n",
              "      <td>0.044403</td>\n",
              "      <td>0.116255</td>\n",
              "      <td>0.039248</td>\n",
              "      <td>0.042539</td>\n",
              "      <td>0.040826</td>\n",
              "      <td>0.180104</td>\n",
              "      <td>6.0</td>\n",
              "      <td>217.957447</td>\n",
              "      <td>1.000120</td>\n",
              "      <td>1.000215</td>\n",
              "      <td>0.023306</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>0.000896</td>\n",
              "      <td>0.013391</td>\n",
              "      <td>1.000312</td>\n",
              "      <td>21.072549</td>\n",
              "      <td>1.000290</td>\n",
              "      <td>9.008105</td>\n",
              "      <td>1.000265</td>\n",
              "      <td>0.011795</td>\n",
              "      <td>1.000237</td>\n",
              "      <td>7.865477</td>\n",
              "      <td>1.000206</td>\n",
              "      <td>1.000171</td>\n",
              "      <td>1.000133</td>\n",
              "      <td>0.000208</td>\n",
              "      <td>1.000092</td>\n",
              "      <td>1.557969</td>\n",
              "      <td>1.000048</td>\n",
              "      <td>1.000048</td>\n",
              "      <td>8.676361</td>\n",
              "      <td>0.000347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/right/signal5 (1).out72</th>\n",
              "      <td>0.000056</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.000235</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.013151</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>0.008576</td>\n",
              "      <td>0.008251</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>-9.480906</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000241</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>-5.050037</td>\n",
              "      <td>1.148428</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.010935</td>\n",
              "      <td>0.005803</td>\n",
              "      <td>0.003995</td>\n",
              "      <td>3090.378496</td>\n",
              "      <td>3089.891606</td>\n",
              "      <td>3089.371987</td>\n",
              "      <td>3249.0</td>\n",
              "      <td>6381.0</td>\n",
              "      <td>3609.0</td>\n",
              "      <td>7807.819605</td>\n",
              "      <td>5.729357e-13</td>\n",
              "      <td>6.312317e-13</td>\n",
              "      <td>12465.791932</td>\n",
              "      <td>-2.589104</td>\n",
              "      <td>-0.063820</td>\n",
              "      <td>0.952925</td>\n",
              "      <td>4.564550</td>\n",
              "      <td>45599.857737</td>\n",
              "      <td>45599.857737</td>\n",
              "      <td>1.713186e-13</td>\n",
              "      <td>562.255481</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.746559e-07</td>\n",
              "      <td>0.000571</td>\n",
              "      <td>1243.347133</td>\n",
              "      <td>8.714162</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000270</td>\n",
              "      <td>925.529636</td>\n",
              "      <td>0.020339</td>\n",
              "      <td>0.013462</td>\n",
              "      <td>0.019179</td>\n",
              "      <td>0.019937</td>\n",
              "      <td>0.019551</td>\n",
              "      <td>0.184987</td>\n",
              "      <td>6.0</td>\n",
              "      <td>209.076222</td>\n",
              "      <td>1.001057</td>\n",
              "      <td>1.001227</td>\n",
              "      <td>0.036050</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>0.001411</td>\n",
              "      <td>0.014012</td>\n",
              "      <td>1.000740</td>\n",
              "      <td>21.086147</td>\n",
              "      <td>1.000671</td>\n",
              "      <td>4.283951</td>\n",
              "      <td>1.000599</td>\n",
              "      <td>0.013311</td>\n",
              "      <td>1.000524</td>\n",
              "      <td>7.770133</td>\n",
              "      <td>1.000445</td>\n",
              "      <td>1.000363</td>\n",
              "      <td>1.000277</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>1.000188</td>\n",
              "      <td>1.536154</td>\n",
              "      <td>1.000096</td>\n",
              "      <td>1.000096</td>\n",
              "      <td>5.785825</td>\n",
              "      <td>0.000353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/right/signal5 (1).out73</th>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.000056</td>\n",
              "      <td>0.013641</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>0.009202</td>\n",
              "      <td>0.009165</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>-9.480809</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000224</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>-5.043491</td>\n",
              "      <td>1.169938</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.010767</td>\n",
              "      <td>0.006932</td>\n",
              "      <td>0.004767</td>\n",
              "      <td>3083.866549</td>\n",
              "      <td>3083.334501</td>\n",
              "      <td>3082.770162</td>\n",
              "      <td>3239.0</td>\n",
              "      <td>6751.0</td>\n",
              "      <td>3239.0</td>\n",
              "      <td>10259.191994</td>\n",
              "      <td>6.671947e-13</td>\n",
              "      <td>5.636845e-13</td>\n",
              "      <td>10938.530791</td>\n",
              "      <td>-2.343415</td>\n",
              "      <td>-0.080695</td>\n",
              "      <td>0.951328</td>\n",
              "      <td>4.719019</td>\n",
              "      <td>47142.995068</td>\n",
              "      <td>47142.995068</td>\n",
              "      <td>1.159670e-13</td>\n",
              "      <td>1502.017765</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.537607e-06</td>\n",
              "      <td>0.000544</td>\n",
              "      <td>781.305262</td>\n",
              "      <td>8.714136</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000265</td>\n",
              "      <td>753.499121</td>\n",
              "      <td>0.020355</td>\n",
              "      <td>0.002331</td>\n",
              "      <td>0.019181</td>\n",
              "      <td>0.019948</td>\n",
              "      <td>0.019557</td>\n",
              "      <td>0.184152</td>\n",
              "      <td>6.0</td>\n",
              "      <td>227.876860</td>\n",
              "      <td>1.001047</td>\n",
              "      <td>1.001214</td>\n",
              "      <td>0.072778</td>\n",
              "      <td>0.000698</td>\n",
              "      <td>0.002880</td>\n",
              "      <td>0.013722</td>\n",
              "      <td>1.000734</td>\n",
              "      <td>21.322879</td>\n",
              "      <td>1.000666</td>\n",
              "      <td>10.868030</td>\n",
              "      <td>1.000594</td>\n",
              "      <td>0.012342</td>\n",
              "      <td>1.000520</td>\n",
              "      <td>7.808782</td>\n",
              "      <td>1.000442</td>\n",
              "      <td>1.000360</td>\n",
              "      <td>1.000275</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>1.000187</td>\n",
              "      <td>1.557959</td>\n",
              "      <td>1.000095</td>\n",
              "      <td>1.000095</td>\n",
              "      <td>10.040468</td>\n",
              "      <td>0.000313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/right/signal5 (1).out74</th>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>0.008543</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>0.006309</td>\n",
              "      <td>0.005995</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>-8.414519</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000184</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>-3.249596</td>\n",
              "      <td>1.280618</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.008714</td>\n",
              "      <td>0.004722</td>\n",
              "      <td>0.004076</td>\n",
              "      <td>3110.238229</td>\n",
              "      <td>3109.686771</td>\n",
              "      <td>3109.102179</td>\n",
              "      <td>3233.0</td>\n",
              "      <td>6757.0</td>\n",
              "      <td>3233.0</td>\n",
              "      <td>10855.484229</td>\n",
              "      <td>2.480804e-13</td>\n",
              "      <td>1.536382e-13</td>\n",
              "      <td>9737.555322</td>\n",
              "      <td>-2.235789</td>\n",
              "      <td>-0.034784</td>\n",
              "      <td>0.955559</td>\n",
              "      <td>4.823562</td>\n",
              "      <td>48187.380837</td>\n",
              "      <td>48187.380837</td>\n",
              "      <td>2.267574e-14</td>\n",
              "      <td>1522.986161</td>\n",
              "      <td>0.000202</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.344653e-06</td>\n",
              "      <td>0.000533</td>\n",
              "      <td>1176.136918</td>\n",
              "      <td>8.714136</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>682.073903</td>\n",
              "      <td>0.097672</td>\n",
              "      <td>0.003761</td>\n",
              "      <td>0.075552</td>\n",
              "      <td>0.088987</td>\n",
              "      <td>0.081721</td>\n",
              "      <td>0.179573</td>\n",
              "      <td>6.0</td>\n",
              "      <td>222.236473</td>\n",
              "      <td>0.999712</td>\n",
              "      <td>0.999925</td>\n",
              "      <td>0.094397</td>\n",
              "      <td>0.000908</td>\n",
              "      <td>0.003745</td>\n",
              "      <td>0.012942</td>\n",
              "      <td>1.000134</td>\n",
              "      <td>21.474425</td>\n",
              "      <td>1.000132</td>\n",
              "      <td>4.339818</td>\n",
              "      <td>1.000127</td>\n",
              "      <td>0.011123</td>\n",
              "      <td>1.000118</td>\n",
              "      <td>7.982640</td>\n",
              "      <td>1.000107</td>\n",
              "      <td>1.000092</td>\n",
              "      <td>1.000074</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>1.000052</td>\n",
              "      <td>1.605494</td>\n",
              "      <td>1.000028</td>\n",
              "      <td>1.000028</td>\n",
              "      <td>10.534030</td>\n",
              "      <td>0.000296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FT_samples/right/signal5 (1).out75</th>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.003963</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.003867</td>\n",
              "      <td>0.005284</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>-3.977984</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>-2.327535</td>\n",
              "      <td>1.378578</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.007929</td>\n",
              "      <td>0.005946</td>\n",
              "      <td>0.003770</td>\n",
              "      <td>3129.934976</td>\n",
              "      <td>3129.380785</td>\n",
              "      <td>3128.792756</td>\n",
              "      <td>3201.0</td>\n",
              "      <td>6789.0</td>\n",
              "      <td>3201.0</td>\n",
              "      <td>11554.606070</td>\n",
              "      <td>3.084703e-13</td>\n",
              "      <td>4.125194e-13</td>\n",
              "      <td>10094.618847</td>\n",
              "      <td>-1.705311</td>\n",
              "      <td>-0.042250</td>\n",
              "      <td>0.954895</td>\n",
              "      <td>5.354665</td>\n",
              "      <td>53493.099945</td>\n",
              "      <td>53493.099945</td>\n",
              "      <td>1.150092e-13</td>\n",
              "      <td>1115.093474</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-4.353377e-07</td>\n",
              "      <td>0.000539</td>\n",
              "      <td>1087.392300</td>\n",
              "      <td>8.714136</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000268</td>\n",
              "      <td>516.260782</td>\n",
              "      <td>-4.184311</td>\n",
              "      <td>0.003913</td>\n",
              "      <td>0.362197</td>\n",
              "      <td>1.314034</td>\n",
              "      <td>0.567861</td>\n",
              "      <td>0.182247</td>\n",
              "      <td>8.0</td>\n",
              "      <td>61.143065</td>\n",
              "      <td>0.999346</td>\n",
              "      <td>0.999566</td>\n",
              "      <td>0.116605</td>\n",
              "      <td>0.001123</td>\n",
              "      <td>0.004631</td>\n",
              "      <td>0.013301</td>\n",
              "      <td>0.999981</td>\n",
              "      <td>19.811737</td>\n",
              "      <td>0.999997</td>\n",
              "      <td>7.120038</td>\n",
              "      <td>1.000009</td>\n",
              "      <td>0.011993</td>\n",
              "      <td>1.000018</td>\n",
              "      <td>8.193574</td>\n",
              "      <td>1.000023</td>\n",
              "      <td>1.000025</td>\n",
              "      <td>1.000024</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>1.000019</td>\n",
              "      <td>1.635966</td>\n",
              "      <td>1.000011</td>\n",
              "      <td>1.000011</td>\n",
              "      <td>7.911676</td>\n",
              "      <td>0.000305</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>232 rows × 222 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.0  ...  value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.8__ql_0.4\n",
              "id                                                                                                    ...                                                                   \n",
              "FT_samples/left/signal.out105                                                0.000391                 ...                                           0.000730                \n",
              "FT_samples/left/signal.out106                                                0.000818                 ...                                           0.002083                \n",
              "FT_samples/left/signal.out13                                                 0.000406                 ...                                           0.000067                \n",
              "FT_samples/left/signal.out14                                                 0.000932                 ...                                           0.000286                \n",
              "FT_samples/left/signal.out15                                                 0.000992                 ...                                           0.000260                \n",
              "...                                                                               ...                 ...                                                ...                \n",
              "FT_samples/right/signal5 (1).out71                                           0.000054                 ...                                           0.000347                \n",
              "FT_samples/right/signal5 (1).out72                                           0.000056                 ...                                           0.000353                \n",
              "FT_samples/right/signal5 (1).out73                                           0.000051                 ...                                           0.000313                \n",
              "FT_samples/right/signal5 (1).out74                                           0.000032                 ...                                           0.000296                \n",
              "FT_samples/right/signal5 (1).out75                                           0.000006                 ...                                           0.000305                \n",
              "\n",
              "[232 rows x 222 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr6G8L6yG3ms",
        "outputId": "f87c4a55-f806-478b-ec19-c8f28de0c3cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "cv_steps = 20\n",
        "\n",
        "eff_acc_array = np.empty(cv_steps)\n",
        "\n",
        "for i in range(cv_steps):\n",
        "    print(\"cv\", i + 1, \"of\", cv_steps)\n",
        "    train_X, test_X, train_y, test_y = train_test_split(efficient_features, y_raw, test_size=0.1, random_state=i, shuffle = True)\n",
        "    \n",
        "    RF_model.fit(train_X, train_y)\n",
        "    \n",
        "    RF_predictions = RF_model.predict(test_X)\n",
        "    acc_score = accuracy_score(test_y ,RF_predictions)\n",
        "    print(acc_score)\n",
        "\n",
        "    eff_acc_array[i] = acc_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv 1 of 20\n",
            "0.9166666666666666\n",
            "cv 2 of 20\n",
            "0.9583333333333334\n",
            "cv 3 of 20\n",
            "0.875\n",
            "cv 4 of 20\n",
            "0.9583333333333334\n",
            "cv 5 of 20\n",
            "0.875\n",
            "cv 6 of 20\n",
            "0.8333333333333334\n",
            "cv 7 of 20\n",
            "0.875\n",
            "cv 8 of 20\n",
            "0.8333333333333334\n",
            "cv 9 of 20\n",
            "0.8333333333333334\n",
            "cv 10 of 20\n",
            "0.7083333333333334\n",
            "cv 11 of 20\n",
            "0.9583333333333334\n",
            "cv 12 of 20\n",
            "0.9166666666666666\n",
            "cv 13 of 20\n",
            "0.875\n",
            "cv 14 of 20\n",
            "0.9166666666666666\n",
            "cv 15 of 20\n",
            "0.9166666666666666\n",
            "cv 16 of 20\n",
            "1.0\n",
            "cv 17 of 20\n",
            "0.75\n",
            "cv 18 of 20\n",
            "0.875\n",
            "cv 19 of 20\n",
            "0.875\n",
            "cv 20 of 20\n",
            "0.8333333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ8QOBqZG7j-",
        "outputId": "8d0302cb-8c86-446f-b466-78804346ac32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
        "\n",
        "f, axes = plt.subplots(3, 1, figsize=(7, 7), sharex=True)\n",
        "axes[0].set_title(\"Random Forest 20 fold CV, Raw Data\")\n",
        "axes[1].set_title(\"Random Forest 20 fold CV, Minimal Feature Extraction\")\n",
        "axes[2].set_title(\"Random Forest 20 fold CV, Efficient Feature Extraction\")\n",
        "sns.distplot(raw_acc_array, hist=True, rug=True, bins = 50, color=\"r\", ax=axes[0])\n",
        "sns.distplot(min_acc_array, hist=True, rug=True, bins = 50, color=\"r\", ax=axes[1])\n",
        "sns.distplot(eff_acc_array, hist=True, rug=True, bins = 50, color=\"r\", ax=axes[2])\n",
        "\n",
        "plt.setp(axes, yticks=[])\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAHsCAYAAAAQKp5gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 504x504 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tstE1KiB1XU3"
      },
      "source": [
        "As it can be seen from above, the model with the Minimal Feature Extraction returns the highest validation accuracy. \n",
        "\n",
        "The Efficient Feature method selects 232 calculated features that the package determined were significant. However from the CV results we can see that this does not help improve accuracy we postulate this could be due to the following.\n",
        "\n",
        "*   A small training set.\n",
        "*   Not enough variance in samples.\n",
        "*   The curse of dimensionality that leads us to overfit when we include too many features\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTSb_RBr6I6E"
      },
      "source": [
        "# Implementation\n",
        "\n",
        ">   \n",
        "*   A hardware API for BYB Spikerbox to read EEG signals.\n",
        "*   High accuracy real time machine learning classifier.\n",
        "*   Web enabled dashboard.\n",
        "\n",
        "Our implementation of our classification model is described with the following algorithm:\n",
        " \n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1VPZBGGvVxFUkSe857QmXVMAzwLf4ah6L\" alt=\"Algorithm\" width=450/>\n",
        "</center>\n",
        "\n",
        "Our classifier currently features a 90% prediction accuracy with a refresh rate of ~ 1 second per prediction. The main loop is implemented in Python and primarily uses numpy operations to transform the data. The API reads data from the arduino, which is fed to our classifier which produces a prediction, in the form of a string of characters 'L', 'R', 'N', 'F'. This is then sent to a dashboard which can be customised to detect specific sequences by searching the string using a simple regular expression.\n",
        "\n",
        "When a sequence is detected a popup and sound notification is sent to the browser to inform the user that a patient has requested assistance.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1z7n7itcV5lko6e8pVS8d2pFKU8wF8Iu7\" alt=\"Dashboard\" width=450/>\n",
        "</center>\n",
        "\n",
        "The dashboard was implemented using Node-Red which handles UI and requests from the server. This enables multiple users to few the dashboard on any internet enabled device in real time. The pipeline of data is best described in the following diagram:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1apM_bzktFcdJ2zk4NjDfM3erZW8Pm6Zo\" alt=\"Product pipeline\" width=600/>\n",
        "</center>\n",
        "\n",
        "[Can be viewed in higher resolution here](https://drive.google.com/uc?id=1apM_bzktFcdJ2zk4NjDfM3erZW8Pm6Zo)\n",
        "\n",
        "Although we demonstrated a high level of accuracy when fitting our random forest models, there was sa significant bottleneck in real time feature extraction.\n",
        "\n",
        "The feature extraction package we used was not intended to be used in real time. We experienced a significant reduction in speed performance of the application when we included mnore features. To account for this we tested a baseline model of a random forest and then added the most useful features iteratively until we found an acceptable middleground between speed and accuracy.\n",
        "\n",
        "Generating features from a sample in realtime using the tsfeatures package could take up to four minutes for a single prediction, which is completely infeasible. We found the optimal speed and accuracy of the application by using these features:\n",
        "\n",
        "**value__minimum, value__mean,\tvalue__sum_values,\tvalue__standard_deviation,\tvalue__variance,\tvalue__maximum,\tvalue__median**\n",
        "\n",
        "Granted these a very simplistic features, but that is a result of their calculations being fast to perform. For further development of this project, we could experiment with custom implementations of important features that are efficiently calculated.\n",
        "\n",
        "We could also try to predict over a smaller sampling windows as this should increase speed of the application.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K_RZmJ_Xivl"
      },
      "source": [
        "#Final Remarks\n",
        "\n",
        "Overall it can be concluded from this report that given the nature of the training data the random forest with minimal feature extraction using the tsfresh package is best for when optimizing both for prediction accuracy and speed of prediction. With regard to data pre-processing, labelling the data using the method based on zero-crossing of the waveform was not accurate. Rather, hand-labelling the training data was found to produce better validation accuracy for the model built on it and our final product was able to predict the command to call a nurse based on eye-movement sequence with 90% accuracy.\n",
        " \n",
        "The product could nonetheless be improved in the following aspects. A larger training set would possibly allow the more complex models to predict with better accuracy, although hand-labelling these would be time-consuming. The device speed could possibly be improved by optimise the filtering and reducing the number of features extracted although this could possibly hamper the prediction accuracy – thus more research could be done as to how this trade-off can be handled. Lastly, the device can be upgraded such that it is able to support multiple patients at once and that a patient is able to customise the eye-sequence they wish to use to call the nurse. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIkWasg_hfvE"
      },
      "source": [
        "#References\n",
        "\n",
        "1. The Brief History of Brain Computer Interfaces, April 4, 2014, http://www.brainvision.co.uk/blog/2014/04/the-brief-history-of-brain-computer-interfaces/\n",
        "2. DeloiteASSIST Transforming patient communication through artificial intelligence, https://www2.deloitte.com/nz/en/pages/life-sciences-and-healthcare/articles/deloitte-assist-transforming-patient-communication.html\n",
        " "
      ]
    }
  ]
}
